
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Introduction: Home Credit Default Risk Competition &#8212; Home Credit Default Risk Assessment</title>
    
  <link rel="stylesheet" href="_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="_static/sphinx-book-theme.2d2078699c18a0efb88233928e1cf6ed.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/language_data.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.be0a4a0c39cd630af62a2fcf693f3f06.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Process train and test files" href="application_train_test.html" />
    <link rel="prev" title="Home Credit Default Risk Assessment" href="landing-page.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="index.html">
  
  <img src="_static/FORE.jpg" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Home Credit Default Risk Assessment</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="landing-page.html">
   Home Credit Default Risk Assessment
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Get started
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Introduction: Home Credit Default Risk Competition
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="#data">
   Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="#exploratory-data-analysis">
   Exploratory Data Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="#feature-engineering">
   Feature Engineering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="#baseline">
   Baseline
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="#conclusions">
   Conclusions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="#just-for-fun-light-gradient-boosting-machine">
   Just for Fun: Light Gradient Boosting Machine
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Process train/test
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="application_train_test.html">
   Process train and test files
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Process Bureau data
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="bureau.html">
   Bureau and Bureau Balance data
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Process POS data
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="pos_cash_balance.html">
   POS Cash balance
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Process Earlier applications data
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="previous_applications.html">
   Previous Applications
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Process Credit Card Data
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="credit_card_balance.html">
   Credit Card balance data
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Installments payment data
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="installments_payments.html">
   Install payments
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Merging all processed data
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="join_all_processed.html">
   Joining all processed data
  </a>
 </li>
</ul>

</nav>

 <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    
    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/start-here-a-gentle-introduction.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
    
</div>
        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/start-here-a-gentle-introduction.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Introduction: Home Credit Default Risk Competition
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data">
   Data
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#metric-roc-auc">
     Metric: ROC AUC
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#imports">
     Imports
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#domain-knowledge-features">
     Domain Knowledge Features
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#read-in-data">
     Read in Data
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exploratory-data-analysis">
   Exploratory Data Analysis
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#examine-the-distribution-of-the-target-column">
     Examine the Distribution of the Target Column
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#examine-missing-values">
     Examine Missing Values
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#column-types">
     Column Types
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#encoding-categorical-variables">
     Encoding Categorical Variables
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#label-encoding-and-one-hot-encoding">
       Label Encoding and One-Hot Encoding
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#aligning-training-and-testing-data">
       Aligning Training and Testing Data
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#back-to-exploratory-data-analysis">
     Back to Exploratory Data Analysis
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#anomalies">
       Anomalies
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#correlations">
       Correlations
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#effect-of-age-on-repayment">
       Effect of Age on Repayment
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#exterior-sources">
       Exterior Sources
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#pairs-plot">
     Pairs Plot
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#feature-engineering">
   Feature Engineering
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#polynomial-features">
     Polynomial Features
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     Domain Knowledge Features
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#visualize-new-variables">
       Visualize New Variables
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#baseline">
   Baseline
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#logistic-regression-implementation">
     Logistic Regression Implementation
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#improved-model-random-forest">
     Improved Model: Random Forest
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#make-predictions-using-engineered-features">
       Make Predictions using Engineered Features
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#testing-domain-features">
         Testing Domain Features
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#model-interpretation-feature-importances">
     Model Interpretation: Feature Importances
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#conclusions">
   Conclusions
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#follow-up-notebooks">
     Follow-up Notebooks
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#just-for-fun-light-gradient-boosting-machine">
   Just for Fun: Light Gradient Boosting Machine
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="introduction-home-credit-default-risk-competition">
<h1>Introduction: Home Credit Default Risk Competition<a class="headerlink" href="#introduction-home-credit-default-risk-competition" title="Permalink to this headline">¶</a></h1>
<p>This notebook is intended for those who are new to machine learning competitions or want a gentle introduction to the problem. I purposely avoid jumping into complicated models or joining together lots of data in order to show the basics of how to get started in machine learning! Any comments or suggestions are much appreciated.</p>
<p>In this notebook, we will take an initial look at the Home Credit default risk machine learning competition currently hosted on Kaggle. The objective of this competition is to use historical loan application data to predict whether or not an applicant will be able to repay a loan. This is a standard supervised classification task:</p>
<ul class="simple">
<li><p><strong>Supervised</strong>: The labels are included in the training data and the goal is to train a model to learn to predict the labels from the features</p></li>
<li><p><strong>Classification</strong>: The label is a binary variable, 0 (will repay loan on time), 1 (will have difficulty repaying loan)</p></li>
</ul>
</div>
<div class="section" id="data">
<h1>Data<a class="headerlink" href="#data" title="Permalink to this headline">¶</a></h1>
<p>The data is provided by <a class="reference external" href="http://www.homecredit.net/about-us.aspx">Home Credit</a>, a service dedicated to provided lines of credit (loans) to the unbanked population. Predicting whether or not a client will repay a loan or have difficulty is a critical business need, and Home Credit is hosting this competition on Kaggle to see what sort of models the machine learning community can develop to help them in this task.</p>
<p>There are 7 different sources of data:</p>
<ul class="simple">
<li><p>application_train/application_test: the main training and testing data with information about each loan application at Home Credit. Every loan has its own row and is identified by the feature <code class="docutils literal notranslate"><span class="pre">SK_ID_CURR</span></code>. The training application data comes with the <code class="docutils literal notranslate"><span class="pre">TARGET</span></code> indicating 0: the loan was repaid or 1: the loan was not repaid.</p></li>
<li><p>bureau: data concerning client’s previous credits from other financial institutions. Each previous credit has its own row in bureau, but one loan in the application data can have multiple previous credits.</p></li>
<li><p>bureau_balance: monthly data about the previous credits in bureau. Each row is one month of a previous credit, and a single previous credit can have multiple rows, one for each month of the credit length.</p></li>
<li><p>previous_application: previous applications for loans at Home Credit of clients who have loans in the application data. Each current loan in the application data can have multiple previous loans. Each previous application has one row and is identified by the feature <code class="docutils literal notranslate"><span class="pre">SK_ID_PREV</span></code>.</p></li>
<li><p>POS_CASH_BALANCE: monthly data about previous point of sale or cash loans clients have had with Home Credit. Each row is one month of a previous point of sale or cash loan, and a single previous loan can have many rows.</p></li>
<li><p>credit_card_balance: monthly data about previous credit cards clients have had with Home Credit. Each row is one month of a credit card balance, and a single credit card can have many rows.</p></li>
<li><p>installments_payment: payment history for previous loans at Home Credit. There is one row for every made payment and one row for every missed payment.</p></li>
</ul>
<p>This diagram shows how all of the data is related:</p>
<p><img alt="image" src="https://storage.googleapis.com/kaggle-media/competitions/home-credit/home_credit.png" /></p>
<p>Moreover, we are provided with the definitions of all the columns (in <code class="docutils literal notranslate"><span class="pre">HomeCredit_columns_description.csv</span></code>) and an example of the expected submission file.</p>
<p>In this notebook, we will stick to using only the main application training and testing data. Although if we want to have any hope of seriously competing, we need to use all the data, for now we will stick to one file which should be more manageable. This will let us establish a baseline that we can then improve upon. With these projects, it’s best to build up an understanding of the problem a little at a time rather than diving all the way in and getting completely lost!</p>
<div class="section" id="metric-roc-auc">
<h2>Metric: ROC AUC<a class="headerlink" href="#metric-roc-auc" title="Permalink to this headline">¶</a></h2>
<p>Once we have a grasp of the data (reading through the <a class="reference external" href="https://www.kaggle.com/c/home-credit-default-risk/data">column descriptions</a> helps immensely), we need to understand the metric by which our submission is judged. In this case, it is a common classification metric known as the <a class="reference external" href="https://stats.stackexchange.com/questions/132777/what-does-auc-stand-for-and-what-is-it">Receiver Operating Characteristic Area Under the Curve (ROC AUC, also sometimes called AUROC)</a>.</p>
<p>The ROC AUC may sound intimidating, but it is relatively straightforward once you can get your head around the two individual concepts. The <a class="reference external" href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic">Reciever Operating Characteristic (ROC) curve</a> graphs the true positive rate versus the false positive rate:</p>
<p><img alt="image" src="http://www.statisticshowto.com/wp-content/uploads/2016/08/ROC-curve.png" /></p>
<p>A single line on the graph indicates the curve for a single model, and movement along a line indicates changing the threshold used for classifying a positive instance. The threshold starts at 0 in the upper right to and goes to 1 in the lower left. A curve that is to the left and above another curve indicates a better model. For example, the blue model is better than the red model, which is better than the black diagonal line which indicates a naive random guessing model.</p>
<p>The <a class="reference external" href="http://gim.unmc.edu/dxtests/roc3.htm">Area Under the Curve (AUC)</a> explains itself by its name! It is simply the area under the ROC curve. (This is the integral of the curve.) This metric is between 0 and 1 with a better model scoring higher. A model that simply guesses at random will have an ROC AUC of 0.5.</p>
<p>When we measure a classifier according to the ROC AUC, we do not generation 0 or 1 predictions, but rather a probability between 0 and 1. This may be confusing because we usually like to think in terms of accuracy, but when we get into problems with inbalanced classes (we will see this is the case), accuracy is not the best metric. For example, if I wanted to build a model that could detect terrorists with 99.9999% accuracy, I would simply make a model that predicted every single person was not a terrorist. Clearly, this would not be effective (the recall would be zero) and we use more advanced metrics such as ROC AUC or the <a class="reference external" href="https://en.wikipedia.org/wiki/F1_score">F1 score</a> to more accurately reflect the performance of a classifier. A model with a high ROC AUC will also have a high accuracy, but the <a class="reference external" href="https://datascience.stackexchange.com/questions/806/advantages-of-auc-vs-standard-accuracy">ROC AUC is a better representation of model performance.</a></p>
<p>Not that we know the background of the data we are using and the metric to maximize, let’s get into exploring the data. In this notebook, as mentioned previously, we will stick to the main data sources and simple models which we can build upon in future work.</p>
<p><strong>Follow-up Notebooks</strong></p>
<p>For those looking to keep working on this problem, I have a series of follow-up notebooks:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://www.kaggle.com/willkoehrsen/introduction-to-manual-feature-engineering">Manual Feature Engineering Part One</a></p></li>
<li><p><a class="reference external" href="https://www.kaggle.com/willkoehrsen/introduction-to-manual-feature-engineering-p2">Manual Feature Engineering Part Two</a></p></li>
<li><p><a class="reference external" href="https://www.kaggle.com/willkoehrsen/automated-feature-engineering-basics">Introduction to Automated Feature Engineering</a></p></li>
<li><p><a class="reference external" href="https://www.kaggle.com/willkoehrsen/tuning-automated-feature-engineering-exploratory">Advanced Automated Feature Engineering</a></p></li>
<li><p><a class="reference external" href="https://www.kaggle.com/willkoehrsen/introduction-to-feature-selection">Feature Selection</a></p></li>
<li><p><a class="reference external" href="https://www.kaggle.com/willkoehrsen/intro-to-model-tuning-grid-and-random-search">Intro to Model Tuning: Grid and Random Search</a></p></li>
<li><p><a class="reference external" href="https://www.kaggle.com/willkoehrsen/automated-model-tuning">Automated Model Tuning</a></p></li>
<li><p><a class="reference external" href="https://www.kaggle.com/willkoehrsen/model-tuning-results-random-vs-bayesian-opt/notebook">Model Tuning Results</a></p></li>
</ul>
<p><strong>More references</strong></p>
<ul class="simple">
<li><p><a class="reference external" href="https://myscore.cibil.com/CreditView/creditEducation.page?enterprise=CIBIL&amp;_ga=2.245893574.372615569.1603669858-164953316.1602941832&amp;_gac=1.254345978.1602941832.CjwKCAjwrKr8BRB_EiwA7eFaplQtBsmINtLxLHOCalWYdx-uO20kyaj0AvRVD8WKNO4cj5mP7MoBTRoC6TEQAvD_BwE">Credit Education</a></p></li>
<li><p><a class="reference external" href="https://www.paisadukan.com/credit-assessment-methodology">Credit Appraisal Methodology and Statndards</a></p></li>
</ul>
<p>I’ll add more notebooks as I finish them! Thanks for all the comments!</p>
</div>
<div class="section" id="imports">
<h2>Imports<a class="headerlink" href="#imports" title="Permalink to this headline">¶</a></h2>
<p>We are using a typical data science stack: <code class="docutils literal notranslate"><span class="pre">numpy</span></code>, <code class="docutils literal notranslate"><span class="pre">pandas</span></code>, <code class="docutils literal notranslate"><span class="pre">sklearn</span></code>, <code class="docutils literal notranslate"><span class="pre">matplotlib</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># numpy and pandas for data manipulation</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span> 

<span class="c1"># sklearn preprocessing for dealing with categorical variables</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>

<span class="c1"># File system manangement</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="c1"># Suppress warnings </span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>

<span class="c1"># matplotlib and seaborn for plotting</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">os</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">IPython.core.interactiveshell</span> <span class="kn">import</span> <span class="n">InteractiveShell</span>
<span class="n">InteractiveShell</span><span class="o">.</span><span class="n">ast_node_interactivity</span> <span class="o">=</span> <span class="s2">&quot;all&quot;</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.max_rows&#39;</span><span class="p">,</span> <span class="mi">500</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.max_colwidth&#39;</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pathToData</span> <span class="o">=</span> <span class="s2">&quot;C:</span><span class="se">\\</span><span class="s2">Users</span><span class="se">\\</span><span class="s2">Administrator</span><span class="se">\\</span><span class="s2">OneDrive</span><span class="se">\\</span><span class="s2">Documents</span><span class="se">\\</span><span class="s2">home_credit_default_risk&quot;</span>
<span class="n">os</span><span class="o">.</span><span class="n">chdir</span><span class="p">(</span><span class="n">pathToData</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;.ipynb_checkpoints&#39;,
 &#39;application_test.csv.zip&#39;,
 &#39;application_train.csv&#39;,
 &#39;application_train.csv.zip&#39;,
 &#39;Automated Loan Repayment.ipynb&#39;,
 &#39;bureau.csv&#39;,
 &#39;bureau.csv.zip&#39;,
 &#39;bureau_balance.csv&#39;,
 &#39;bureau_balance.csv.zip&#39;,
 &#39;credit_card_balance.csv&#39;,
 &#39;credit_card_balance.csv.zip&#39;,
 &#39;HomeCredit_columns_description.csv&#39;,
 &#39;installments_payments.csv&#39;,
 &#39;installments_payments.csv.zip&#39;,
 &#39;kaggle link.txt&#39;,
 &#39;POS_CASH_balance.csv&#39;,
 &#39;POS_CASH_balance.csv.zip&#39;,
 &#39;previous_application.csv&#39;,
 &#39;previous_application.csv.zip&#39;,
 &#39;sample_submission.csv&#39;,
 &#39;start-here-a-gentle-introduction.ipynb&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">app_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;application_train.csv&quot;</span><span class="p">)</span>
<span class="n">app_test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;application_test.csv.zip&quot;</span><span class="p">)</span>
<span class="n">app_train</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
<span class="n">app_train</span><span class="o">.</span><span class="n">shape</span>   <span class="c1"># (307511, 122)</span>
<span class="n">app_train</span><span class="o">.</span><span class="n">dtypes</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SK_ID_CURR</th>
      <th>TARGET</th>
      <th>NAME_CONTRACT_TYPE</th>
      <th>CODE_GENDER</th>
      <th>FLAG_OWN_CAR</th>
      <th>FLAG_OWN_REALTY</th>
      <th>CNT_CHILDREN</th>
      <th>AMT_INCOME_TOTAL</th>
      <th>AMT_CREDIT</th>
      <th>AMT_ANNUITY</th>
      <th>...</th>
      <th>FLAG_DOCUMENT_18</th>
      <th>FLAG_DOCUMENT_19</th>
      <th>FLAG_DOCUMENT_20</th>
      <th>FLAG_DOCUMENT_21</th>
      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>
      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>
      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>
      <th>AMT_REQ_CREDIT_BUREAU_MON</th>
      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>
      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>100002</td>
      <td>1</td>
      <td>Cash loans</td>
      <td>M</td>
      <td>N</td>
      <td>Y</td>
      <td>0</td>
      <td>202500.0</td>
      <td>406597.5</td>
      <td>24700.5</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>100003</td>
      <td>0</td>
      <td>Cash loans</td>
      <td>F</td>
      <td>N</td>
      <td>N</td>
      <td>0</td>
      <td>270000.0</td>
      <td>1293502.5</td>
      <td>35698.5</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>100004</td>
      <td>0</td>
      <td>Revolving loans</td>
      <td>M</td>
      <td>Y</td>
      <td>Y</td>
      <td>0</td>
      <td>67500.0</td>
      <td>135000.0</td>
      <td>6750.0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>100006</td>
      <td>0</td>
      <td>Cash loans</td>
      <td>F</td>
      <td>N</td>
      <td>Y</td>
      <td>0</td>
      <td>135000.0</td>
      <td>312682.5</td>
      <td>29686.5</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>4</th>
      <td>100007</td>
      <td>0</td>
      <td>Cash loans</td>
      <td>M</td>
      <td>N</td>
      <td>Y</td>
      <td>0</td>
      <td>121500.0</td>
      <td>513000.0</td>
      <td>21865.5</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 122 columns</p>
</div></div><div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(307511, 122)
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>SK_ID_CURR                      int64  
TARGET                          int64  
NAME_CONTRACT_TYPE              object 
CODE_GENDER                     object 
FLAG_OWN_CAR                    object 
FLAG_OWN_REALTY                 object 
CNT_CHILDREN                    int64  
AMT_INCOME_TOTAL                float64
AMT_CREDIT                      float64
AMT_ANNUITY                     float64
AMT_GOODS_PRICE                 float64
NAME_TYPE_SUITE                 object 
NAME_INCOME_TYPE                object 
NAME_EDUCATION_TYPE             object 
NAME_FAMILY_STATUS              object 
NAME_HOUSING_TYPE               object 
REGION_POPULATION_RELATIVE      float64
DAYS_BIRTH                      int64  
DAYS_EMPLOYED                   int64  
DAYS_REGISTRATION               float64
DAYS_ID_PUBLISH                 int64  
OWN_CAR_AGE                     float64
FLAG_MOBIL                      int64  
FLAG_EMP_PHONE                  int64  
FLAG_WORK_PHONE                 int64  
FLAG_CONT_MOBILE                int64  
FLAG_PHONE                      int64  
FLAG_EMAIL                      int64  
OCCUPATION_TYPE                 object 
CNT_FAM_MEMBERS                 float64
REGION_RATING_CLIENT            int64  
REGION_RATING_CLIENT_W_CITY     int64  
WEEKDAY_APPR_PROCESS_START      object 
HOUR_APPR_PROCESS_START         int64  
REG_REGION_NOT_LIVE_REGION      int64  
REG_REGION_NOT_WORK_REGION      int64  
LIVE_REGION_NOT_WORK_REGION     int64  
REG_CITY_NOT_LIVE_CITY          int64  
REG_CITY_NOT_WORK_CITY          int64  
LIVE_CITY_NOT_WORK_CITY         int64  
ORGANIZATION_TYPE               object 
EXT_SOURCE_1                    float64
EXT_SOURCE_2                    float64
EXT_SOURCE_3                    float64
APARTMENTS_AVG                  float64
BASEMENTAREA_AVG                float64
YEARS_BEGINEXPLUATATION_AVG     float64
YEARS_BUILD_AVG                 float64
COMMONAREA_AVG                  float64
ELEVATORS_AVG                   float64
ENTRANCES_AVG                   float64
FLOORSMAX_AVG                   float64
FLOORSMIN_AVG                   float64
LANDAREA_AVG                    float64
LIVINGAPARTMENTS_AVG            float64
LIVINGAREA_AVG                  float64
NONLIVINGAPARTMENTS_AVG         float64
NONLIVINGAREA_AVG               float64
APARTMENTS_MODE                 float64
BASEMENTAREA_MODE               float64
YEARS_BEGINEXPLUATATION_MODE    float64
YEARS_BUILD_MODE                float64
COMMONAREA_MODE                 float64
ELEVATORS_MODE                  float64
ENTRANCES_MODE                  float64
FLOORSMAX_MODE                  float64
FLOORSMIN_MODE                  float64
LANDAREA_MODE                   float64
LIVINGAPARTMENTS_MODE           float64
LIVINGAREA_MODE                 float64
NONLIVINGAPARTMENTS_MODE        float64
NONLIVINGAREA_MODE              float64
APARTMENTS_MEDI                 float64
BASEMENTAREA_MEDI               float64
YEARS_BEGINEXPLUATATION_MEDI    float64
YEARS_BUILD_MEDI                float64
COMMONAREA_MEDI                 float64
ELEVATORS_MEDI                  float64
ENTRANCES_MEDI                  float64
FLOORSMAX_MEDI                  float64
FLOORSMIN_MEDI                  float64
LANDAREA_MEDI                   float64
LIVINGAPARTMENTS_MEDI           float64
LIVINGAREA_MEDI                 float64
NONLIVINGAPARTMENTS_MEDI        float64
NONLIVINGAREA_MEDI              float64
FONDKAPREMONT_MODE              object 
HOUSETYPE_MODE                  object 
TOTALAREA_MODE                  float64
WALLSMATERIAL_MODE              object 
EMERGENCYSTATE_MODE             object 
OBS_30_CNT_SOCIAL_CIRCLE        float64
DEF_30_CNT_SOCIAL_CIRCLE        float64
OBS_60_CNT_SOCIAL_CIRCLE        float64
DEF_60_CNT_SOCIAL_CIRCLE        float64
DAYS_LAST_PHONE_CHANGE          float64
FLAG_DOCUMENT_2                 int64  
FLAG_DOCUMENT_3                 int64  
FLAG_DOCUMENT_4                 int64  
FLAG_DOCUMENT_5                 int64  
FLAG_DOCUMENT_6                 int64  
FLAG_DOCUMENT_7                 int64  
FLAG_DOCUMENT_8                 int64  
FLAG_DOCUMENT_9                 int64  
FLAG_DOCUMENT_10                int64  
FLAG_DOCUMENT_11                int64  
FLAG_DOCUMENT_12                int64  
FLAG_DOCUMENT_13                int64  
FLAG_DOCUMENT_14                int64  
FLAG_DOCUMENT_15                int64  
FLAG_DOCUMENT_16                int64  
FLAG_DOCUMENT_17                int64  
FLAG_DOCUMENT_18                int64  
FLAG_DOCUMENT_19                int64  
FLAG_DOCUMENT_20                int64  
FLAG_DOCUMENT_21                int64  
AMT_REQ_CREDIT_BUREAU_HOUR      float64
AMT_REQ_CREDIT_BUREAU_DAY       float64
AMT_REQ_CREDIT_BUREAU_WEEK      float64
AMT_REQ_CREDIT_BUREAU_MON       float64
AMT_REQ_CREDIT_BUREAU_QRT       float64
AMT_REQ_CREDIT_BUREAU_YEAR      float64
dtype: object
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">col_desc</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;HomeCredit_columns_description.csv&quot;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span> <span class="s1">&#39;unicode_escape&#39;</span><span class="p">)</span>
<span class="n">col_desc</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="mi">122</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Table</th>
      <th>Row</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>application_{train|test}.csv</td>
      <td>SK_ID_CURR</td>
      <td>ID of loan in our sample</td>
    </tr>
    <tr>
      <th>1</th>
      <td>application_{train|test}.csv</td>
      <td>TARGET</td>
      <td>Target variable (1 - client with payment difficulties: he/she had late payment more than X days on at least one of the first Y installments of the loan in our sample, 0 - all other cases)</td>
    </tr>
    <tr>
      <th>2</th>
      <td>application_{train|test}.csv</td>
      <td>NAME_CONTRACT_TYPE</td>
      <td>Identification if loan is cash or revolving</td>
    </tr>
    <tr>
      <th>3</th>
      <td>application_{train|test}.csv</td>
      <td>CODE_GENDER</td>
      <td>Gender of the client</td>
    </tr>
    <tr>
      <th>4</th>
      <td>application_{train|test}.csv</td>
      <td>FLAG_OWN_CAR</td>
      <td>Flag if the client owns a car</td>
    </tr>
    <tr>
      <th>5</th>
      <td>application_{train|test}.csv</td>
      <td>FLAG_OWN_REALTY</td>
      <td>Flag if client owns a house or flat</td>
    </tr>
    <tr>
      <th>6</th>
      <td>application_{train|test}.csv</td>
      <td>CNT_CHILDREN</td>
      <td>Number of children the client has</td>
    </tr>
    <tr>
      <th>7</th>
      <td>application_{train|test}.csv</td>
      <td>AMT_INCOME_TOTAL</td>
      <td>Income of the client</td>
    </tr>
    <tr>
      <th>8</th>
      <td>application_{train|test}.csv</td>
      <td>AMT_CREDIT</td>
      <td>Credit amount of the loan</td>
    </tr>
    <tr>
      <th>9</th>
      <td>application_{train|test}.csv</td>
      <td>AMT_ANNUITY</td>
      <td>Loan annuity</td>
    </tr>
    <tr>
      <th>10</th>
      <td>application_{train|test}.csv</td>
      <td>AMT_GOODS_PRICE</td>
      <td>For consumer loans it is the price of the goods for which the loan is given</td>
    </tr>
    <tr>
      <th>11</th>
      <td>application_{train|test}.csv</td>
      <td>NAME_TYPE_SUITE</td>
      <td>Who was accompanying client when he was applying for the loan</td>
    </tr>
    <tr>
      <th>12</th>
      <td>application_{train|test}.csv</td>
      <td>NAME_INCOME_TYPE</td>
      <td>Clients income type (businessman, working, maternity leave,)</td>
    </tr>
    <tr>
      <th>13</th>
      <td>application_{train|test}.csv</td>
      <td>NAME_EDUCATION_TYPE</td>
      <td>Level of highest education the client achieved</td>
    </tr>
    <tr>
      <th>14</th>
      <td>application_{train|test}.csv</td>
      <td>NAME_FAMILY_STATUS</td>
      <td>Family status of the client</td>
    </tr>
    <tr>
      <th>15</th>
      <td>application_{train|test}.csv</td>
      <td>NAME_HOUSING_TYPE</td>
      <td>What is the housing situation of the client (renting, living with parents, ...)</td>
    </tr>
    <tr>
      <th>16</th>
      <td>application_{train|test}.csv</td>
      <td>REGION_POPULATION_RELATIVE</td>
      <td>Normalized population of region where client lives (higher number means the client lives in more populated region)</td>
    </tr>
    <tr>
      <th>17</th>
      <td>application_{train|test}.csv</td>
      <td>DAYS_BIRTH</td>
      <td>Client's age in days at the time of application</td>
    </tr>
    <tr>
      <th>18</th>
      <td>application_{train|test}.csv</td>
      <td>DAYS_EMPLOYED</td>
      <td>How many days before the application the person started current employment</td>
    </tr>
    <tr>
      <th>19</th>
      <td>application_{train|test}.csv</td>
      <td>DAYS_REGISTRATION</td>
      <td>How many days before the application did client change his registration</td>
    </tr>
    <tr>
      <th>20</th>
      <td>application_{train|test}.csv</td>
      <td>DAYS_ID_PUBLISH</td>
      <td>How many days before the application did client change the identity document with which he applied for the loan</td>
    </tr>
    <tr>
      <th>21</th>
      <td>application_{train|test}.csv</td>
      <td>OWN_CAR_AGE</td>
      <td>Age of client's car</td>
    </tr>
    <tr>
      <th>22</th>
      <td>application_{train|test}.csv</td>
      <td>FLAG_MOBIL</td>
      <td>Did client provide mobile phone (1=YES, 0=NO)</td>
    </tr>
    <tr>
      <th>23</th>
      <td>application_{train|test}.csv</td>
      <td>FLAG_EMP_PHONE</td>
      <td>Did client provide work phone (1=YES, 0=NO)</td>
    </tr>
    <tr>
      <th>24</th>
      <td>application_{train|test}.csv</td>
      <td>FLAG_WORK_PHONE</td>
      <td>Did client provide home phone (1=YES, 0=NO)</td>
    </tr>
    <tr>
      <th>25</th>
      <td>application_{train|test}.csv</td>
      <td>FLAG_CONT_MOBILE</td>
      <td>Was mobile phone reachable (1=YES, 0=NO)</td>
    </tr>
    <tr>
      <th>26</th>
      <td>application_{train|test}.csv</td>
      <td>FLAG_PHONE</td>
      <td>Did client provide home phone (1=YES, 0=NO)</td>
    </tr>
    <tr>
      <th>27</th>
      <td>application_{train|test}.csv</td>
      <td>FLAG_EMAIL</td>
      <td>Did client provide email (1=YES, 0=NO)</td>
    </tr>
    <tr>
      <th>28</th>
      <td>application_{train|test}.csv</td>
      <td>OCCUPATION_TYPE</td>
      <td>What kind of occupation does the client have</td>
    </tr>
    <tr>
      <th>29</th>
      <td>application_{train|test}.csv</td>
      <td>CNT_FAM_MEMBERS</td>
      <td>How many family members does client have</td>
    </tr>
    <tr>
      <th>30</th>
      <td>application_{train|test}.csv</td>
      <td>REGION_RATING_CLIENT</td>
      <td>Our rating of the region where client lives (1,2,3)</td>
    </tr>
    <tr>
      <th>31</th>
      <td>application_{train|test}.csv</td>
      <td>REGION_RATING_CLIENT_W_CITY</td>
      <td>Our rating of the region where client lives with taking city into account (1,2,3)</td>
    </tr>
    <tr>
      <th>32</th>
      <td>application_{train|test}.csv</td>
      <td>WEEKDAY_APPR_PROCESS_START</td>
      <td>On which day of the week did the client apply for the loan</td>
    </tr>
    <tr>
      <th>33</th>
      <td>application_{train|test}.csv</td>
      <td>HOUR_APPR_PROCESS_START</td>
      <td>Approximately at what hour did the client apply for the loan</td>
    </tr>
    <tr>
      <th>34</th>
      <td>application_{train|test}.csv</td>
      <td>REG_REGION_NOT_LIVE_REGION</td>
      <td>Flag if client's permanent address does not match contact address (1=different, 0=same, at region level)</td>
    </tr>
    <tr>
      <th>35</th>
      <td>application_{train|test}.csv</td>
      <td>REG_REGION_NOT_WORK_REGION</td>
      <td>Flag if client's permanent address does not match work address (1=different, 0=same, at region level)</td>
    </tr>
    <tr>
      <th>36</th>
      <td>application_{train|test}.csv</td>
      <td>LIVE_REGION_NOT_WORK_REGION</td>
      <td>Flag if client's contact address does not match work address (1=different, 0=same, at region level)</td>
    </tr>
    <tr>
      <th>37</th>
      <td>application_{train|test}.csv</td>
      <td>REG_CITY_NOT_LIVE_CITY</td>
      <td>Flag if client's permanent address does not match contact address (1=different, 0=same, at city level)</td>
    </tr>
    <tr>
      <th>38</th>
      <td>application_{train|test}.csv</td>
      <td>REG_CITY_NOT_WORK_CITY</td>
      <td>Flag if client's permanent address does not match work address (1=different, 0=same, at city level)</td>
    </tr>
    <tr>
      <th>39</th>
      <td>application_{train|test}.csv</td>
      <td>LIVE_CITY_NOT_WORK_CITY</td>
      <td>Flag if client's contact address does not match work address (1=different, 0=same, at city level)</td>
    </tr>
    <tr>
      <th>40</th>
      <td>application_{train|test}.csv</td>
      <td>ORGANIZATION_TYPE</td>
      <td>Type of organization where client works</td>
    </tr>
    <tr>
      <th>41</th>
      <td>application_{train|test}.csv</td>
      <td>EXT_SOURCE_1</td>
      <td>Normalized score from external data source</td>
    </tr>
    <tr>
      <th>42</th>
      <td>application_{train|test}.csv</td>
      <td>EXT_SOURCE_2</td>
      <td>Normalized score from external data source</td>
    </tr>
    <tr>
      <th>43</th>
      <td>application_{train|test}.csv</td>
      <td>EXT_SOURCE_3</td>
      <td>Normalized score from external data source</td>
    </tr>
    <tr>
      <th>44</th>
      <td>application_{train|test}.csv</td>
      <td>APARTMENTS_AVG</td>
      <td>Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td>
    </tr>
    <tr>
      <th>45</th>
      <td>application_{train|test}.csv</td>
      <td>BASEMENTAREA_AVG</td>
      <td>Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td>
    </tr>
    <tr>
      <th>46</th>
      <td>application_{train|test}.csv</td>
      <td>YEARS_BEGINEXPLUATATION_AVG</td>
      <td>Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td>
    </tr>
    <tr>
      <th>47</th>
      <td>application_{train|test}.csv</td>
      <td>YEARS_BUILD_AVG</td>
      <td>Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td>
    </tr>
    <tr>
      <th>48</th>
      <td>application_{train|test}.csv</td>
      <td>COMMONAREA_AVG</td>
      <td>Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td>
    </tr>
    <tr>
      <th>49</th>
      <td>application_{train|test}.csv</td>
      <td>ELEVATORS_AVG</td>
      <td>Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td>
    </tr>
    <tr>
      <th>50</th>
      <td>application_{train|test}.csv</td>
      <td>ENTRANCES_AVG</td>
      <td>Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td>
    </tr>
    <tr>
      <th>51</th>
      <td>application_{train|test}.csv</td>
      <td>FLOORSMAX_AVG</td>
      <td>Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td>
    </tr>
    <tr>
      <th>52</th>
      <td>application_{train|test}.csv</td>
      <td>FLOORSMIN_AVG</td>
      <td>Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td>
    </tr>
    <tr>
      <th>53</th>
      <td>application_{train|test}.csv</td>
      <td>LANDAREA_AVG</td>
      <td>Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td>
    </tr>
    <tr>
      <th>54</th>
      <td>application_{train|test}.csv</td>
      <td>LIVINGAPARTMENTS_AVG</td>
      <td>Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td>
    </tr>
    <tr>
      <th>55</th>
      <td>application_{train|test}.csv</td>
      <td>LIVINGAREA_AVG</td>
      <td>Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td>
    </tr>
    <tr>
      <th>56</th>
      <td>application_{train|test}.csv</td>
      <td>NONLIVINGAPARTMENTS_AVG</td>
      <td>Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td>
    </tr>
    <tr>
      <th>57</th>
      <td>application_{train|test}.csv</td>
      <td>NONLIVINGAREA_AVG</td>
      <td>Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td>
    </tr>
    <tr>
      <th>58</th>
      <td>application_{train|test}.csv</td>
      <td>APARTMENTS_MODE</td>
      <td>Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td>
    </tr>
    <tr>
      <th>59</th>
      <td>application_{train|test}.csv</td>
      <td>BASEMENTAREA_MODE</td>
      <td>Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td>
    </tr>
    <tr>
      <th>60</th>
      <td>application_{train|test}.csv</td>
      <td>YEARS_BEGINEXPLUATATION_MODE</td>
      <td>Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td>
    </tr>
    <tr>
      <th>61</th>
      <td>application_{train|test}.csv</td>
      <td>YEARS_BUILD_MODE</td>
      <td>Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td>
    </tr>
    <tr>
      <th>62</th>
      <td>application_{train|test}.csv</td>
      <td>COMMONAREA_MODE</td>
      <td>Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td>
    </tr>
    <tr>
      <th>63</th>
      <td>application_{train|test}.csv</td>
      <td>ELEVATORS_MODE</td>
      <td>Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td>
    </tr>
    <tr>
      <th>64</th>
      <td>application_{train|test}.csv</td>
      <td>ENTRANCES_MODE</td>
      <td>Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td>
    </tr>
    <tr>
      <th>65</th>
      <td>application_{train|test}.csv</td>
      <td>FLOORSMAX_MODE</td>
      <td>Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td>
    </tr>
    <tr>
      <th>66</th>
      <td>application_{train|test}.csv</td>
      <td>FLOORSMIN_MODE</td>
      <td>Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td>
    </tr>
    <tr>
      <th>67</th>
      <td>application_{train|test}.csv</td>
      <td>LANDAREA_MODE</td>
      <td>Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td>
    </tr>
    <tr>
      <th>68</th>
      <td>application_{train|test}.csv</td>
      <td>LIVINGAPARTMENTS_MODE</td>
      <td>Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td>
    </tr>
    <tr>
      <th>69</th>
      <td>application_{train|test}.csv</td>
      <td>LIVINGAREA_MODE</td>
      <td>Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td>
    </tr>
    <tr>
      <th>70</th>
      <td>application_{train|test}.csv</td>
      <td>NONLIVINGAPARTMENTS_MODE</td>
      <td>Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td>
    </tr>
    <tr>
      <th>71</th>
      <td>application_{train|test}.csv</td>
      <td>NONLIVINGAREA_MODE</td>
      <td>Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td>
    </tr>
    <tr>
      <th>72</th>
      <td>application_{train|test}.csv</td>
      <td>APARTMENTS_MEDI</td>
      <td>Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td>
    </tr>
    <tr>
      <th>73</th>
      <td>application_{train|test}.csv</td>
      <td>BASEMENTAREA_MEDI</td>
      <td>Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td>
    </tr>
    <tr>
      <th>74</th>
      <td>application_{train|test}.csv</td>
      <td>YEARS_BEGINEXPLUATATION_MEDI</td>
      <td>Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td>
    </tr>
    <tr>
      <th>75</th>
      <td>application_{train|test}.csv</td>
      <td>YEARS_BUILD_MEDI</td>
      <td>Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td>
    </tr>
    <tr>
      <th>76</th>
      <td>application_{train|test}.csv</td>
      <td>COMMONAREA_MEDI</td>
      <td>Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td>
    </tr>
    <tr>
      <th>77</th>
      <td>application_{train|test}.csv</td>
      <td>ELEVATORS_MEDI</td>
      <td>Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td>
    </tr>
    <tr>
      <th>78</th>
      <td>application_{train|test}.csv</td>
      <td>ENTRANCES_MEDI</td>
      <td>Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td>
    </tr>
    <tr>
      <th>79</th>
      <td>application_{train|test}.csv</td>
      <td>FLOORSMAX_MEDI</td>
      <td>Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td>
    </tr>
    <tr>
      <th>80</th>
      <td>application_{train|test}.csv</td>
      <td>FLOORSMIN_MEDI</td>
      <td>Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td>
    </tr>
    <tr>
      <th>81</th>
      <td>application_{train|test}.csv</td>
      <td>LANDAREA_MEDI</td>
      <td>Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td>
    </tr>
    <tr>
      <th>82</th>
      <td>application_{train|test}.csv</td>
      <td>LIVINGAPARTMENTS_MEDI</td>
      <td>Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td>
    </tr>
    <tr>
      <th>83</th>
      <td>application_{train|test}.csv</td>
      <td>LIVINGAREA_MEDI</td>
      <td>Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td>
    </tr>
    <tr>
      <th>84</th>
      <td>application_{train|test}.csv</td>
      <td>NONLIVINGAPARTMENTS_MEDI</td>
      <td>Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td>
    </tr>
    <tr>
      <th>85</th>
      <td>application_{train|test}.csv</td>
      <td>NONLIVINGAREA_MEDI</td>
      <td>Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td>
    </tr>
    <tr>
      <th>86</th>
      <td>application_{train|test}.csv</td>
      <td>FONDKAPREMONT_MODE</td>
      <td>Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td>
    </tr>
    <tr>
      <th>87</th>
      <td>application_{train|test}.csv</td>
      <td>HOUSETYPE_MODE</td>
      <td>Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td>
    </tr>
    <tr>
      <th>88</th>
      <td>application_{train|test}.csv</td>
      <td>TOTALAREA_MODE</td>
      <td>Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td>
    </tr>
    <tr>
      <th>89</th>
      <td>application_{train|test}.csv</td>
      <td>WALLSMATERIAL_MODE</td>
      <td>Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td>
    </tr>
    <tr>
      <th>90</th>
      <td>application_{train|test}.csv</td>
      <td>EMERGENCYSTATE_MODE</td>
      <td>Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td>
    </tr>
    <tr>
      <th>91</th>
      <td>application_{train|test}.csv</td>
      <td>OBS_30_CNT_SOCIAL_CIRCLE</td>
      <td>How many observation of client's social surroundings with observable 30 DPD (days past due) default</td>
    </tr>
    <tr>
      <th>92</th>
      <td>application_{train|test}.csv</td>
      <td>DEF_30_CNT_SOCIAL_CIRCLE</td>
      <td>How many observation of client's social surroundings defaulted on 30 DPD (days past due)</td>
    </tr>
    <tr>
      <th>93</th>
      <td>application_{train|test}.csv</td>
      <td>OBS_60_CNT_SOCIAL_CIRCLE</td>
      <td>How many observation of client's social surroundings with observable 60 DPD (days past due) default</td>
    </tr>
    <tr>
      <th>94</th>
      <td>application_{train|test}.csv</td>
      <td>DEF_60_CNT_SOCIAL_CIRCLE</td>
      <td>How many observation of client's social surroundings defaulted on 60 (days past due) DPD</td>
    </tr>
    <tr>
      <th>95</th>
      <td>application_{train|test}.csv</td>
      <td>DAYS_LAST_PHONE_CHANGE</td>
      <td>How many days before application did client change phone</td>
    </tr>
    <tr>
      <th>96</th>
      <td>application_{train|test}.csv</td>
      <td>FLAG_DOCUMENT_2</td>
      <td>Did client provide document 2</td>
    </tr>
    <tr>
      <th>97</th>
      <td>application_{train|test}.csv</td>
      <td>FLAG_DOCUMENT_3</td>
      <td>Did client provide document 3</td>
    </tr>
    <tr>
      <th>98</th>
      <td>application_{train|test}.csv</td>
      <td>FLAG_DOCUMENT_4</td>
      <td>Did client provide document 4</td>
    </tr>
    <tr>
      <th>99</th>
      <td>application_{train|test}.csv</td>
      <td>FLAG_DOCUMENT_5</td>
      <td>Did client provide document 5</td>
    </tr>
    <tr>
      <th>100</th>
      <td>application_{train|test}.csv</td>
      <td>FLAG_DOCUMENT_6</td>
      <td>Did client provide document 6</td>
    </tr>
    <tr>
      <th>101</th>
      <td>application_{train|test}.csv</td>
      <td>FLAG_DOCUMENT_7</td>
      <td>Did client provide document 7</td>
    </tr>
    <tr>
      <th>102</th>
      <td>application_{train|test}.csv</td>
      <td>FLAG_DOCUMENT_8</td>
      <td>Did client provide document 8</td>
    </tr>
    <tr>
      <th>103</th>
      <td>application_{train|test}.csv</td>
      <td>FLAG_DOCUMENT_9</td>
      <td>Did client provide document 9</td>
    </tr>
    <tr>
      <th>104</th>
      <td>application_{train|test}.csv</td>
      <td>FLAG_DOCUMENT_10</td>
      <td>Did client provide document 10</td>
    </tr>
    <tr>
      <th>105</th>
      <td>application_{train|test}.csv</td>
      <td>FLAG_DOCUMENT_11</td>
      <td>Did client provide document 11</td>
    </tr>
    <tr>
      <th>106</th>
      <td>application_{train|test}.csv</td>
      <td>FLAG_DOCUMENT_12</td>
      <td>Did client provide document 12</td>
    </tr>
    <tr>
      <th>107</th>
      <td>application_{train|test}.csv</td>
      <td>FLAG_DOCUMENT_13</td>
      <td>Did client provide document 13</td>
    </tr>
    <tr>
      <th>108</th>
      <td>application_{train|test}.csv</td>
      <td>FLAG_DOCUMENT_14</td>
      <td>Did client provide document 14</td>
    </tr>
    <tr>
      <th>109</th>
      <td>application_{train|test}.csv</td>
      <td>FLAG_DOCUMENT_15</td>
      <td>Did client provide document 15</td>
    </tr>
    <tr>
      <th>110</th>
      <td>application_{train|test}.csv</td>
      <td>FLAG_DOCUMENT_16</td>
      <td>Did client provide document 16</td>
    </tr>
    <tr>
      <th>111</th>
      <td>application_{train|test}.csv</td>
      <td>FLAG_DOCUMENT_17</td>
      <td>Did client provide document 17</td>
    </tr>
    <tr>
      <th>112</th>
      <td>application_{train|test}.csv</td>
      <td>FLAG_DOCUMENT_18</td>
      <td>Did client provide document 18</td>
    </tr>
    <tr>
      <th>113</th>
      <td>application_{train|test}.csv</td>
      <td>FLAG_DOCUMENT_19</td>
      <td>Did client provide document 19</td>
    </tr>
    <tr>
      <th>114</th>
      <td>application_{train|test}.csv</td>
      <td>FLAG_DOCUMENT_20</td>
      <td>Did client provide document 20</td>
    </tr>
    <tr>
      <th>115</th>
      <td>application_{train|test}.csv</td>
      <td>FLAG_DOCUMENT_21</td>
      <td>Did client provide document 21</td>
    </tr>
    <tr>
      <th>116</th>
      <td>application_{train|test}.csv</td>
      <td>AMT_REQ_CREDIT_BUREAU_HOUR</td>
      <td>Number of enquiries to Credit Bureau about the client one hour before application</td>
    </tr>
    <tr>
      <th>117</th>
      <td>application_{train|test}.csv</td>
      <td>AMT_REQ_CREDIT_BUREAU_DAY</td>
      <td>Number of enquiries to Credit Bureau about the client one day before application (excluding one hour before application)</td>
    </tr>
    <tr>
      <th>118</th>
      <td>application_{train|test}.csv</td>
      <td>AMT_REQ_CREDIT_BUREAU_WEEK</td>
      <td>Number of enquiries to Credit Bureau about the client one week before application (excluding one day before application)</td>
    </tr>
    <tr>
      <th>119</th>
      <td>application_{train|test}.csv</td>
      <td>AMT_REQ_CREDIT_BUREAU_MON</td>
      <td>Number of enquiries to Credit Bureau about the client one month before application (excluding one week before application)</td>
    </tr>
    <tr>
      <th>120</th>
      <td>application_{train|test}.csv</td>
      <td>AMT_REQ_CREDIT_BUREAU_QRT</td>
      <td>Number of enquiries to Credit Bureau about the client 3 month before application (excluding one month before application)</td>
    </tr>
    <tr>
      <th>121</th>
      <td>application_{train|test}.csv</td>
      <td>AMT_REQ_CREDIT_BUREAU_YEAR</td>
      <td>Number of enquiries to Credit Bureau about the client one day year (excluding last 3 months before application)</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</div>
<div class="section" id="domain-knowledge-features">
<h2>Domain Knowledge Features<a class="headerlink" href="#domain-knowledge-features" title="Permalink to this headline">¶</a></h2>
<p>Some features generated through domain knowledge to help the algorithm:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">CREDIT_INCOME_PERCENT</span></code>: the percentage of the credit amount relative to a client’s income</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ANNUITY_INCOME_PERCENT</span></code>: the percentage of the loan annuity relative to a client’s income</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">CREDIT_TERM</span></code>:  the length of the payment in months (since the annuity is the monthly amount due</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">DAYS_EMPLOYED_PERCENT</span></code>: the percentage of the days employed relative to the client’s age</p></li>
</ul>
<p>Again, thanks to Aguiar and <a class="reference external" href="https://www.kaggle.com/jsaguiar/updated-0-792-lb-lightgbm-with-simple-features">his great script</a> for exploring these features.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">app_train_domain</span> <span class="o">=</span> <span class="n">app_train</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">app_test_domain</span> <span class="o">=</span> <span class="n">app_test</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

<span class="n">app_train_domain</span><span class="p">[</span><span class="s1">&#39;CREDIT_INCOME_PERCENT&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">app_train_domain</span><span class="p">[</span><span class="s1">&#39;AMT_CREDIT&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">app_train_domain</span><span class="p">[</span><span class="s1">&#39;AMT_INCOME_TOTAL&#39;</span><span class="p">]</span>
<span class="n">app_train_domain</span><span class="p">[</span><span class="s1">&#39;ANNUITY_INCOME_PERCENT&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">app_train_domain</span><span class="p">[</span><span class="s1">&#39;AMT_ANNUITY&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">app_train_domain</span><span class="p">[</span><span class="s1">&#39;AMT_INCOME_TOTAL&#39;</span><span class="p">]</span>
<span class="n">app_train_domain</span><span class="p">[</span><span class="s1">&#39;CREDIT_TERM&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">app_train_domain</span><span class="p">[</span><span class="s1">&#39;AMT_ANNUITY&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">app_train_domain</span><span class="p">[</span><span class="s1">&#39;AMT_CREDIT&#39;</span><span class="p">]</span>
<span class="n">app_train_domain</span><span class="p">[</span><span class="s1">&#39;DAYS_EMPLOYED_PERCENT&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">app_train_domain</span><span class="p">[</span><span class="s1">&#39;DAYS_EMPLOYED&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">app_train_domain</span><span class="p">[</span><span class="s1">&#39;DAYS_BIRTH&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">app_test_domain</span><span class="p">[</span><span class="s1">&#39;CREDIT_INCOME_PERCENT&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">app_test_domain</span><span class="p">[</span><span class="s1">&#39;AMT_CREDIT&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">app_test_domain</span><span class="p">[</span><span class="s1">&#39;AMT_INCOME_TOTAL&#39;</span><span class="p">]</span>
<span class="n">app_test_domain</span><span class="p">[</span><span class="s1">&#39;ANNUITY_INCOME_PERCENT&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">app_test_domain</span><span class="p">[</span><span class="s1">&#39;AMT_ANNUITY&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">app_test_domain</span><span class="p">[</span><span class="s1">&#39;AMT_INCOME_TOTAL&#39;</span><span class="p">]</span>
<span class="n">app_test_domain</span><span class="p">[</span><span class="s1">&#39;CREDIT_TERM&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">app_test_domain</span><span class="p">[</span><span class="s1">&#39;AMT_ANNUITY&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">app_test_domain</span><span class="p">[</span><span class="s1">&#39;AMT_CREDIT&#39;</span><span class="p">]</span>
<span class="n">app_test_domain</span><span class="p">[</span><span class="s1">&#39;DAYS_EMPLOYED_PERCENT&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">app_test_domain</span><span class="p">[</span><span class="s1">&#39;DAYS_EMPLOYED&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">app_test_domain</span><span class="p">[</span><span class="s1">&#39;DAYS_BIRTH&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pre_app</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;previous_application.csv.zip&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pre_app</span><span class="o">.</span><span class="n">shape</span>     <span class="c1"># (1670214, 37)</span>
<span class="n">pre_app</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
<span class="n">pre_app</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(1670214, 37)
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SK_ID_PREV</th>
      <th>SK_ID_CURR</th>
      <th>NAME_CONTRACT_TYPE</th>
      <th>AMT_ANNUITY</th>
      <th>AMT_APPLICATION</th>
      <th>AMT_CREDIT</th>
      <th>AMT_DOWN_PAYMENT</th>
      <th>AMT_GOODS_PRICE</th>
      <th>WEEKDAY_APPR_PROCESS_START</th>
      <th>HOUR_APPR_PROCESS_START</th>
      <th>...</th>
      <th>NAME_SELLER_INDUSTRY</th>
      <th>CNT_PAYMENT</th>
      <th>NAME_YIELD_GROUP</th>
      <th>PRODUCT_COMBINATION</th>
      <th>DAYS_FIRST_DRAWING</th>
      <th>DAYS_FIRST_DUE</th>
      <th>DAYS_LAST_DUE_1ST_VERSION</th>
      <th>DAYS_LAST_DUE</th>
      <th>DAYS_TERMINATION</th>
      <th>NFLAG_INSURED_ON_APPROVAL</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2030495</td>
      <td>271877</td>
      <td>Consumer loans</td>
      <td>1730.430</td>
      <td>17145.0</td>
      <td>17145.0</td>
      <td>0.0</td>
      <td>17145.0</td>
      <td>SATURDAY</td>
      <td>15</td>
      <td>...</td>
      <td>Connectivity</td>
      <td>12.0</td>
      <td>middle</td>
      <td>POS mobile with interest</td>
      <td>365243.0</td>
      <td>-42.0</td>
      <td>300.0</td>
      <td>-42.0</td>
      <td>-37.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2802425</td>
      <td>108129</td>
      <td>Cash loans</td>
      <td>25188.615</td>
      <td>607500.0</td>
      <td>679671.0</td>
      <td>NaN</td>
      <td>607500.0</td>
      <td>THURSDAY</td>
      <td>11</td>
      <td>...</td>
      <td>XNA</td>
      <td>36.0</td>
      <td>low_action</td>
      <td>Cash X-Sell: low</td>
      <td>365243.0</td>
      <td>-134.0</td>
      <td>916.0</td>
      <td>365243.0</td>
      <td>365243.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2523466</td>
      <td>122040</td>
      <td>Cash loans</td>
      <td>15060.735</td>
      <td>112500.0</td>
      <td>136444.5</td>
      <td>NaN</td>
      <td>112500.0</td>
      <td>TUESDAY</td>
      <td>11</td>
      <td>...</td>
      <td>XNA</td>
      <td>12.0</td>
      <td>high</td>
      <td>Cash X-Sell: high</td>
      <td>365243.0</td>
      <td>-271.0</td>
      <td>59.0</td>
      <td>365243.0</td>
      <td>365243.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2819243</td>
      <td>176158</td>
      <td>Cash loans</td>
      <td>47041.335</td>
      <td>450000.0</td>
      <td>470790.0</td>
      <td>NaN</td>
      <td>450000.0</td>
      <td>MONDAY</td>
      <td>7</td>
      <td>...</td>
      <td>XNA</td>
      <td>12.0</td>
      <td>middle</td>
      <td>Cash X-Sell: middle</td>
      <td>365243.0</td>
      <td>-482.0</td>
      <td>-152.0</td>
      <td>-182.0</td>
      <td>-177.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1784265</td>
      <td>202054</td>
      <td>Cash loans</td>
      <td>31924.395</td>
      <td>337500.0</td>
      <td>404055.0</td>
      <td>NaN</td>
      <td>337500.0</td>
      <td>THURSDAY</td>
      <td>9</td>
      <td>...</td>
      <td>XNA</td>
      <td>24.0</td>
      <td>high</td>
      <td>Cash Street: high</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 37 columns</p>
</div></div><div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>RATE_INTEREST_PRIVILEGED       1664263
RATE_INTEREST_PRIMARY          1664263
RATE_DOWN_PAYMENT              895844 
AMT_DOWN_PAYMENT               895844 
NAME_TYPE_SUITE                820405 
DAYS_TERMINATION               673065 
NFLAG_INSURED_ON_APPROVAL      673065 
DAYS_FIRST_DRAWING             673065 
DAYS_FIRST_DUE                 673065 
DAYS_LAST_DUE_1ST_VERSION      673065 
DAYS_LAST_DUE                  673065 
AMT_GOODS_PRICE                385515 
AMT_ANNUITY                    372235 
CNT_PAYMENT                    372230 
PRODUCT_COMBINATION            346    
AMT_CREDIT                     1      
SK_ID_CURR                     0      
NAME_CONTRACT_TYPE             0      
WEEKDAY_APPR_PROCESS_START     0      
HOUR_APPR_PROCESS_START        0      
FLAG_LAST_APPL_PER_CONTRACT    0      
NFLAG_LAST_APPL_IN_DAY         0      
AMT_APPLICATION                0      
NAME_PAYMENT_TYPE              0      
NAME_CASH_LOAN_PURPOSE         0      
NAME_CONTRACT_STATUS           0      
DAYS_DECISION                  0      
CODE_REJECT_REASON             0      
NAME_CLIENT_TYPE               0      
NAME_GOODS_CATEGORY            0      
NAME_PORTFOLIO                 0      
NAME_PRODUCT_TYPE              0      
CHANNEL_TYPE                   0      
SELLERPLACE_AREA               0      
NAME_SELLER_INDUSTRY           0      
NAME_YIELD_GROUP               0      
SK_ID_PREV                     0      
dtype: int64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">col_desc</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">173</span><span class="p">:</span><span class="mi">211</span><span class="p">,</span> <span class="p">:]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sn</th>
      <th>Table</th>
      <th>Row</th>
      <th>Description</th>
      <th>Special</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>173</th>
      <td>176</td>
      <td>previous_application.csv</td>
      <td>SK_ID_PREV</td>
      <td>ID of previous credit in Home credit related to loan in our sample. (One loan in our sample can have 0,1,2 or more previous loan applications in Home Credit, previous application could, but not necessarily have to lead to credit)</td>
      <td>hashed</td>
    </tr>
    <tr>
      <th>174</th>
      <td>177</td>
      <td>previous_application.csv</td>
      <td>SK_ID_CURR</td>
      <td>ID of loan in our sample</td>
      <td>hashed</td>
    </tr>
    <tr>
      <th>175</th>
      <td>178</td>
      <td>previous_application.csv</td>
      <td>NAME_CONTRACT_TYPE</td>
      <td>Contract product type (Cash loan, consumer loan [POS] ,...) of the previous application</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>176</th>
      <td>179</td>
      <td>previous_application.csv</td>
      <td>AMT_ANNUITY</td>
      <td>Annuity of previous application</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>177</th>
      <td>180</td>
      <td>previous_application.csv</td>
      <td>AMT_APPLICATION</td>
      <td>For how much credit did client ask on the previous application</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>178</th>
      <td>181</td>
      <td>previous_application.csv</td>
      <td>AMT_CREDIT</td>
      <td>Final credit amount on the previous application. This differs from AMT_APPLICATION in a way that the AMT_APPLICATION is the amount for which the client initially applied for, but during our approval process he could have received different amount - AMT_CREDIT</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>179</th>
      <td>182</td>
      <td>previous_application.csv</td>
      <td>AMT_DOWN_PAYMENT</td>
      <td>Down payment on the previous application</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>180</th>
      <td>183</td>
      <td>previous_application.csv</td>
      <td>AMT_GOODS_PRICE</td>
      <td>Goods price of good that client asked for (if applicable) on the previous application</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>181</th>
      <td>184</td>
      <td>previous_application.csv</td>
      <td>WEEKDAY_APPR_PROCESS_START</td>
      <td>On which day of the week did the client apply for previous application</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>182</th>
      <td>185</td>
      <td>previous_application.csv</td>
      <td>HOUR_APPR_PROCESS_START</td>
      <td>Approximately at what day hour did the client apply for the previous application</td>
      <td>rounded</td>
    </tr>
    <tr>
      <th>183</th>
      <td>186</td>
      <td>previous_application.csv</td>
      <td>FLAG_LAST_APPL_PER_CONTRACT</td>
      <td>Flag if it was last application for the previous contract. Sometimes by mistake of client or our clerk there could be more applications for one single contract</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>184</th>
      <td>187</td>
      <td>previous_application.csv</td>
      <td>NFLAG_LAST_APPL_IN_DAY</td>
      <td>Flag if the application was the last application per day of the client. Sometimes clients apply for more applications a day. Rarely it could also be error in our system that one application is in the database twice</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>185</th>
      <td>188</td>
      <td>previous_application.csv</td>
      <td>NFLAG_MICRO_CASH</td>
      <td>Flag Micro finance loan</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>186</th>
      <td>189</td>
      <td>previous_application.csv</td>
      <td>RATE_DOWN_PAYMENT</td>
      <td>Down payment rate normalized on previous credit</td>
      <td>normalized</td>
    </tr>
    <tr>
      <th>187</th>
      <td>190</td>
      <td>previous_application.csv</td>
      <td>RATE_INTEREST_PRIMARY</td>
      <td>Interest rate normalized on previous credit</td>
      <td>normalized</td>
    </tr>
    <tr>
      <th>188</th>
      <td>191</td>
      <td>previous_application.csv</td>
      <td>RATE_INTEREST_PRIVILEGED</td>
      <td>Interest rate normalized on previous credit</td>
      <td>normalized</td>
    </tr>
    <tr>
      <th>189</th>
      <td>192</td>
      <td>previous_application.csv</td>
      <td>NAME_CASH_LOAN_PURPOSE</td>
      <td>Purpose of the cash loan</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>190</th>
      <td>193</td>
      <td>previous_application.csv</td>
      <td>NAME_CONTRACT_STATUS</td>
      <td>Contract status (approved, cancelled, ...) of previous application</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>191</th>
      <td>194</td>
      <td>previous_application.csv</td>
      <td>DAYS_DECISION</td>
      <td>Relative to current application when was the decision about previous application made</td>
      <td>time only relative to the application</td>
    </tr>
    <tr>
      <th>192</th>
      <td>195</td>
      <td>previous_application.csv</td>
      <td>NAME_PAYMENT_TYPE</td>
      <td>Payment method that client chose to pay for the previous application</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>193</th>
      <td>196</td>
      <td>previous_application.csv</td>
      <td>CODE_REJECT_REASON</td>
      <td>Why was the previous application rejected</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>194</th>
      <td>197</td>
      <td>previous_application.csv</td>
      <td>NAME_TYPE_SUITE</td>
      <td>Who accompanied client when applying for the previous application</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>195</th>
      <td>198</td>
      <td>previous_application.csv</td>
      <td>NAME_CLIENT_TYPE</td>
      <td>Was the client old or new client when applying for the previous application</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>196</th>
      <td>199</td>
      <td>previous_application.csv</td>
      <td>NAME_GOODS_CATEGORY</td>
      <td>What kind of goods did the client apply for in the previous application</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>197</th>
      <td>200</td>
      <td>previous_application.csv</td>
      <td>NAME_PORTFOLIO</td>
      <td>Was the previous application for CASH, POS, CAR,</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>198</th>
      <td>201</td>
      <td>previous_application.csv</td>
      <td>NAME_PRODUCT_TYPE</td>
      <td>Was the previous application x-sell o walk-in</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>199</th>
      <td>202</td>
      <td>previous_application.csv</td>
      <td>CHANNEL_TYPE</td>
      <td>Through which channel we acquired the client on the previous application</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>200</th>
      <td>203</td>
      <td>previous_application.csv</td>
      <td>SELLERPLACE_AREA</td>
      <td>Selling area of seller place of the previous application</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>201</th>
      <td>204</td>
      <td>previous_application.csv</td>
      <td>NAME_SELLER_INDUSTRY</td>
      <td>The industry of the seller</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>202</th>
      <td>205</td>
      <td>previous_application.csv</td>
      <td>CNT_PAYMENT</td>
      <td>Term of previous credit at application of the previous application</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>203</th>
      <td>206</td>
      <td>previous_application.csv</td>
      <td>NAME_YIELD_GROUP</td>
      <td>Grouped interest rate into small medium and high of the previous application</td>
      <td>grouped</td>
    </tr>
    <tr>
      <th>204</th>
      <td>207</td>
      <td>previous_application.csv</td>
      <td>PRODUCT_COMBINATION</td>
      <td>Detailed product combination of the previous application</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>205</th>
      <td>208</td>
      <td>previous_application.csv</td>
      <td>DAYS_FIRST_DRAWING</td>
      <td>Relative to application date of current application when was the first disbursement of the previous application</td>
      <td>time only relative to the application</td>
    </tr>
    <tr>
      <th>206</th>
      <td>209</td>
      <td>previous_application.csv</td>
      <td>DAYS_FIRST_DUE</td>
      <td>Relative to application date of current application when was the first due supposed to be of the previous application</td>
      <td>time only relative to the application</td>
    </tr>
    <tr>
      <th>207</th>
      <td>210</td>
      <td>previous_application.csv</td>
      <td>DAYS_LAST_DUE_1ST_VERSION</td>
      <td>Relative to application date of current application when was the first due of the previous application</td>
      <td>time only relative to the application</td>
    </tr>
    <tr>
      <th>208</th>
      <td>211</td>
      <td>previous_application.csv</td>
      <td>DAYS_LAST_DUE</td>
      <td>Relative to application date of current application when was the last due date of the previous application</td>
      <td>time only relative to the application</td>
    </tr>
    <tr>
      <th>209</th>
      <td>212</td>
      <td>previous_application.csv</td>
      <td>DAYS_TERMINATION</td>
      <td>Relative to application date of current application when was the expected termination of the previous application</td>
      <td>time only relative to the application</td>
    </tr>
    <tr>
      <th>210</th>
      <td>213</td>
      <td>previous_application.csv</td>
      <td>NFLAG_INSURED_ON_APPROVAL</td>
      <td>Did the client requested insurance during the previous application</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</div>
<div class="section" id="read-in-data">
<h2>Read in Data<a class="headerlink" href="#read-in-data" title="Permalink to this headline">¶</a></h2>
<p>First, we can list all the available data files. There are a total of 9 files: 1 main file for training (with target) 1 main file for testing (without the target), 1 example submission file, and 6 other files containing additional information about each loan.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># List files available</span>
<span class="nb">print</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s2">&quot;../input/&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Training data</span>
<span class="n">app_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;../input/application_train.csv&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Training data shape: &#39;</span><span class="p">,</span> <span class="n">app_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">app_train</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>The training data has 307511 observations (each one a separate loan) and 122 features (variables) including the <code class="docutils literal notranslate"><span class="pre">TARGET</span></code> (the label we want to predict).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Testing data features</span>
<span class="n">app_test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;../input/application_test.csv&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Testing data shape: &#39;</span><span class="p">,</span> <span class="n">app_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">app_test</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>The test set is considerably smaller and lacks a <code class="docutils literal notranslate"><span class="pre">TARGET</span></code> column.</p>
</div>
</div>
<div class="section" id="exploratory-data-analysis">
<h1>Exploratory Data Analysis<a class="headerlink" href="#exploratory-data-analysis" title="Permalink to this headline">¶</a></h1>
<p>Exploratory Data Analysis (EDA) is an open-ended process where we calculate statistics and make figures to find trends, anomalies, patterns, or relationships within the data. The goal of EDA is to learn what our data can tell us. It generally starts out with a high level overview, then narrows in to specific areas as we find intriguing areas of the data. The findings may be interesting in their own right, or they can be used to inform our modeling choices, such as by helping us decide which features to use.</p>
<div class="section" id="examine-the-distribution-of-the-target-column">
<h2>Examine the Distribution of the Target Column<a class="headerlink" href="#examine-the-distribution-of-the-target-column" title="Permalink to this headline">¶</a></h2>
<p>The target is what we are asked to predict: either a 0 for the loan was repaid on time, or a 1 indicating the client had payment difficulties. We can first examine the number of loans falling into each category.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">app_train</span><span class="p">[</span><span class="s1">&#39;TARGET&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">app_train</span><span class="p">[</span><span class="s1">&#39;TARGET&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">hist</span><span class="p">();</span>
</pre></div>
</div>
</div>
</div>
<p>From this information, we see this is an <a class="reference external" href="http://www.chioka.in/class-imbalance-problem/"><em>imbalanced class problem</em></a>. There are far more loans that were repaid on time than loans that were not repaid. Once we get into more sophisticated machine learning models, we can <a class="reference external" href="http://xgboost.readthedocs.io/en/latest/parameter.html">weight the classes</a> by their representation in the data to reflect this imbalance.</p>
</div>
<div class="section" id="examine-missing-values">
<h2>Examine Missing Values<a class="headerlink" href="#examine-missing-values" title="Permalink to this headline">¶</a></h2>
<p>Next we can look at the number and percentage of missing values in each column.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Function to calculate missing values by column# Funct </span>
<span class="k">def</span> <span class="nf">missing_values_table</span><span class="p">(</span><span class="n">df</span><span class="p">):</span>
        <span class="c1"># Total missing values</span>
        <span class="n">mis_val</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        
        <span class="c1"># Percentage of missing values</span>
        <span class="n">mis_val_percent</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">df</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
        
        <span class="c1"># Make a table with the results</span>
        <span class="n">mis_val_table</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">mis_val</span><span class="p">,</span> <span class="n">mis_val_percent</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="c1"># Rename the columns</span>
        <span class="n">mis_val_table_ren_columns</span> <span class="o">=</span> <span class="n">mis_val_table</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span>
        <span class="n">columns</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span> <span class="p">:</span> <span class="s1">&#39;Missing Values&#39;</span><span class="p">,</span> <span class="mi">1</span> <span class="p">:</span> <span class="s1">&#39;</span><span class="si">% o</span><span class="s1">f Total Values&#39;</span><span class="p">})</span>
        
        <span class="c1"># Sort the table by percentage of missing descending</span>
        <span class="n">mis_val_table_ren_columns</span> <span class="o">=</span> <span class="n">mis_val_table_ren_columns</span><span class="p">[</span>
            <span class="n">mis_val_table_ren_columns</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span>
        <span class="s1">&#39;</span><span class="si">% o</span><span class="s1">f Total Values&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="c1"># Print some summary information</span>
        <span class="nb">print</span> <span class="p">(</span><span class="s2">&quot;Your selected dataframe has &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">+</span> <span class="s2">&quot; columns.</span><span class="se">\n</span><span class="s2">&quot;</span>      
            <span class="s2">&quot;There are &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">mis_val_table_ren_columns</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">+</span>
              <span class="s2">&quot; columns that have missing values.&quot;</span><span class="p">)</span>
        
        <span class="c1"># Return the dataframe with missing information</span>
        <span class="k">return</span> <span class="n">mis_val_table_ren_columns</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Missing values statistics</span>
<span class="n">missing_values</span> <span class="o">=</span> <span class="n">missing_values_table</span><span class="p">(</span><span class="n">app_train</span><span class="p">)</span>
<span class="n">missing_values</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>When it comes time to build our machine learning models, we will have to fill in these missing values (known as imputation). In later work, we will use models such as XGBoost that can <a class="reference external" href="https://stats.stackexchange.com/questions/235489/xgboost-can-handle-missing-data-in-the-forecasting-phase">handle missing values with no need for imputation</a>. Another option would be to drop columns with a high percentage of missing values, although it is impossible to know ahead of time if these columns will be helpful to our model. Therefore, we will keep all of the columns for now.</p>
</div>
<div class="section" id="column-types">
<h2>Column Types<a class="headerlink" href="#column-types" title="Permalink to this headline">¶</a></h2>
<p>Let’s look at the number of columns of each data type. <code class="docutils literal notranslate"><span class="pre">int64</span></code> and <code class="docutils literal notranslate"><span class="pre">float64</span></code> are numeric variables (<a class="reference external" href="https://stats.stackexchange.com/questions/206/what-is-the-difference-between-discrete-data-and-continuous-data">which can be either discrete or continuous</a>). <code class="docutils literal notranslate"><span class="pre">object</span></code> columns contain strings and are  <a class="reference external" href="http://support.minitab.com/en-us/minitab-express/1/help-and-how-to/modeling-statistics/regression/supporting-topics/basics/what-are-categorical-discrete-and-continuous-variables/">categorical features.</a> .</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Number of each type of column</span>
<span class="n">app_train</span><span class="o">.</span><span class="n">dtypes</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s now look at the number of unique entries in each of the <code class="docutils literal notranslate"><span class="pre">object</span></code> (categorical) columns.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Number of unique classes in each object column</span>
<span class="n">app_train</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="s1">&#39;object&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="o">.</span><span class="n">nunique</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Most of the categorical variables have a relatively small number of unique entries. We will need to find a way to deal with these categorical variables!</p>
</div>
<div class="section" id="encoding-categorical-variables">
<h2>Encoding Categorical Variables<a class="headerlink" href="#encoding-categorical-variables" title="Permalink to this headline">¶</a></h2>
<p>Before we go any further, we need to deal with pesky categorical variables.  A machine learning model unfortunately cannot deal with categorical variables (except for some models such as <a class="reference external" href="http://lightgbm.readthedocs.io/en/latest/Features.html">LightGBM</a>). Therefore, we have to find a way to encode (represent) these variables as numbers before handing them off to the model. There are two main ways to carry out this process:</p>
<ul class="simple">
<li><p>Label encoding: assign each unique category in a categorical variable with an integer. No new columns are created. An example is shown below</p></li>
</ul>
<p><img alt="image" src="https://raw.githubusercontent.com/WillKoehrsen/Machine-Learning-Projects/master/label_encoding.png" /></p>
<ul class="simple">
<li><p>One-hot encoding: create a new column for each unique category in a categorical variable. Each observation recieves a 1 in the column for its corresponding category and a 0 in all other new columns.</p></li>
</ul>
<p><img alt="image" src="https://raw.githubusercontent.com/WillKoehrsen/Machine-Learning-Projects/master/one_hot_encoding.png" /></p>
<p>The problem with label encoding is that it gives the categories an arbitrary ordering. The value assigned to each of the categories is random and does not reflect any inherent aspect of the category. In the example above, programmer recieves a 4 and data scientist a 1, but if we did the same process again, the labels could be reversed or completely different. The actual assignment of the integers is arbitrary. Therefore, when we perform label encoding, the model might use the relative value of the feature (for example programmer = 4 and data scientist = 1) to assign weights which is not what we want. If we only have two unique values for a categorical variable (such as Male/Female), then label encoding is fine, but for more than 2 unique categories, one-hot encoding is the safe option.</p>
<p>There is some debate about the relative merits of these approaches, and some models can deal with label encoded categorical variables with no issues. <a class="reference external" href="https://datascience.stackexchange.com/questions/9443/when-to-use-one-hot-encoding-vs-labelencoder-vs-dictvectorizor">Here is a good Stack Overflow discussion</a>. I think (and this is just a personal opinion) for categorical variables with many classes, one-hot encoding is the safest approach because it does not impose arbitrary values to categories. The only downside to one-hot encoding is that the number of features (dimensions of the data) can explode with categorical variables with many categories. To deal with this, we can perform one-hot encoding followed by <a class="reference external" href="http://www.cs.otago.ac.nz/cosc453/student_tutorials/principal_components.pdf">PCA</a> or other <a class="reference external" href="https://www.analyticsvidhya.com/blog/2015/07/dimension-reduction-methods/">dimensionality reduction methods</a> to reduce the number of dimensions (while still trying to preserve information).</p>
<p>In this notebook, we will use Label Encoding for any categorical variables with only 2 categories and One-Hot Encoding for any categorical variables with more than 2 categories. This process may need to change as we get further into the project, but for now, we will see where this gets us. (We will also not use any dimensionality reduction in this notebook but will explore in future iterations).</p>
<div class="section" id="label-encoding-and-one-hot-encoding">
<h3>Label Encoding and One-Hot Encoding<a class="headerlink" href="#label-encoding-and-one-hot-encoding" title="Permalink to this headline">¶</a></h3>
<p>Let’s implement the policy described above: for any categorical variable (<code class="docutils literal notranslate"><span class="pre">dtype</span> <span class="pre">==</span> <span class="pre">object</span></code>) with 2 unique categories, we will use label encoding, and for any categorical variable with more than 2 unique categories, we will use one-hot encoding.</p>
<p>For label encoding, we use the Scikit-Learn <code class="docutils literal notranslate"><span class="pre">LabelEncoder</span></code> and for one-hot encoding, the pandas <code class="docutils literal notranslate"><span class="pre">get_dummies(df)</span></code> function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create a label encoder object</span>
<span class="n">le</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">le_count</span> <span class="o">=</span> <span class="mi">0</span>

<span class="c1"># Iterate through the columns</span>
<span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">app_train</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">app_train</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="s1">&#39;object&#39;</span><span class="p">:</span>
        <span class="c1"># If 2 or fewer unique categories</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">app_train</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()))</span> <span class="o">&lt;=</span> <span class="mi">2</span><span class="p">:</span>
            <span class="c1"># Train on the training data</span>
            <span class="n">le</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">app_train</span><span class="p">[</span><span class="n">col</span><span class="p">])</span>
            <span class="c1"># Transform both training and testing data</span>
            <span class="n">app_train</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">le</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">app_train</span><span class="p">[</span><span class="n">col</span><span class="p">])</span>
            <span class="n">app_test</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">le</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">app_test</span><span class="p">[</span><span class="n">col</span><span class="p">])</span>
            
            <span class="c1"># Keep track of how many columns were label encoded</span>
            <span class="n">le_count</span> <span class="o">+=</span> <span class="mi">1</span>
            
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">%d</span><span class="s1"> columns were label encoded.&#39;</span> <span class="o">%</span> <span class="n">le_count</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># one-hot encoding of categorical variables</span>
<span class="n">app_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">app_train</span><span class="p">)</span>
<span class="n">app_test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">app_test</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Training Features shape: &#39;</span><span class="p">,</span> <span class="n">app_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Testing Features shape: &#39;</span><span class="p">,</span> <span class="n">app_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="aligning-training-and-testing-data">
<h3>Aligning Training and Testing Data<a class="headerlink" href="#aligning-training-and-testing-data" title="Permalink to this headline">¶</a></h3>
<p>There need to be the same features (columns) in both the training and testing data. One-hot encoding has created more columns in the training data because there were some categorical variables with categories not represented in the testing data. To remove the columns in the training data that are not in the testing data, we need to <code class="docutils literal notranslate"><span class="pre">align</span></code> the dataframes. First we extract the target column from the training data (because this is not in the testing data but we need to keep this information). When we do the align, we must make sure to set <code class="docutils literal notranslate"><span class="pre">axis</span> <span class="pre">=</span> <span class="pre">1</span></code> to align the dataframes based on the columns and not on the rows!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_labels</span> <span class="o">=</span> <span class="n">app_train</span><span class="p">[</span><span class="s1">&#39;TARGET&#39;</span><span class="p">]</span>

<span class="c1"># Align the training and testing data, keep only columns present in both dataframes</span>
<span class="n">app_train</span><span class="p">,</span> <span class="n">app_test</span> <span class="o">=</span> <span class="n">app_train</span><span class="o">.</span><span class="n">align</span><span class="p">(</span><span class="n">app_test</span><span class="p">,</span> <span class="n">join</span> <span class="o">=</span> <span class="s1">&#39;inner&#39;</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># Add the target back in</span>
<span class="n">app_train</span><span class="p">[</span><span class="s1">&#39;TARGET&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">train_labels</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Training Features shape: &#39;</span><span class="p">,</span> <span class="n">app_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Testing Features shape: &#39;</span><span class="p">,</span> <span class="n">app_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The training and testing datasets now have the same features which is required for machine learning. The number of features has grown significantly due to one-hot encoding. At some point we probably will want to try <a class="reference external" href="https://en.wikipedia.org/wiki/Dimensionality_reduction">dimensionality reduction (removing features that are not relevant)</a> to reduce the size of the datasets.</p>
</div>
</div>
<div class="section" id="back-to-exploratory-data-analysis">
<h2>Back to Exploratory Data Analysis<a class="headerlink" href="#back-to-exploratory-data-analysis" title="Permalink to this headline">¶</a></h2>
<div class="section" id="anomalies">
<h3>Anomalies<a class="headerlink" href="#anomalies" title="Permalink to this headline">¶</a></h3>
<p>One problem we always want to be on the lookout for when doing EDA is anomalies within the data. These may be due to mis-typed numbers, errors in measuring equipment, or they could be valid but extreme measurements. One way to support anomalies quantitatively is by looking at the statistics of a column using the <code class="docutils literal notranslate"><span class="pre">describe</span></code> method. The numbers in the <code class="docutils literal notranslate"><span class="pre">DAYS_BIRTH</span></code> column are negative because they are recorded relative to the current loan application. To see these stats in years, we can mutliple by -1 and divide by the number of days in a year:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="n">app_train</span><span class="p">[</span><span class="s1">&#39;DAYS_BIRTH&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="o">-</span><span class="mi">365</span><span class="p">)</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Those ages look reasonable. There are no outliers for the age on either the high or low end. How about the days of employment?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">app_train</span><span class="p">[</span><span class="s1">&#39;DAYS_EMPLOYED&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>That doesn’t look right! The maximum value (besides being positive) is about 1000 years!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">app_train</span><span class="p">[</span><span class="s1">&#39;DAYS_EMPLOYED&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">title</span> <span class="o">=</span> <span class="s1">&#39;Days Employment Histogram&#39;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Days Employment&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>Just out of curiousity, let’s subset the anomalous clients and see if they tend to have higher or low rates of default than the rest of the clients.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">anom</span> <span class="o">=</span> <span class="n">app_train</span><span class="p">[</span><span class="n">app_train</span><span class="p">[</span><span class="s1">&#39;DAYS_EMPLOYED&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">365243</span><span class="p">]</span>
<span class="n">non_anom</span> <span class="o">=</span> <span class="n">app_train</span><span class="p">[</span><span class="n">app_train</span><span class="p">[</span><span class="s1">&#39;DAYS_EMPLOYED&#39;</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">365243</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;The non-anomalies default on </span><span class="si">%0.2f%%</span><span class="s1"> of loans&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="n">non_anom</span><span class="p">[</span><span class="s1">&#39;TARGET&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;The anomalies default on </span><span class="si">%0.2f%%</span><span class="s1"> of loans&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="n">anom</span><span class="p">[</span><span class="s1">&#39;TARGET&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;There are </span><span class="si">%d</span><span class="s1"> anomalous days of employment&#39;</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">anom</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>Well that is extremely interesting! It turns out that the anomalies have a lower rate of default.</p>
<p>Handling the anomalies depends on the exact situation, with no set rules. One of the safest approaches is just to set the anomalies to a missing value and then have them filled in (using Imputation) before machine learning. In this case, since all the anomalies have the exact same value, we want to fill them in with the same value in case all of these loans share something in common. The anomalous values seem to have some importance, so we want to tell the machine learning model if we did in fact fill in these values. As a solution, we will fill in the anomalous values with not a number (<code class="docutils literal notranslate"><span class="pre">np.nan</span></code>) and then create a new boolean column indicating whether or not the value was anomalous.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create an anomalous flag column</span>
<span class="n">app_train</span><span class="p">[</span><span class="s1">&#39;DAYS_EMPLOYED_ANOM&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">app_train</span><span class="p">[</span><span class="s2">&quot;DAYS_EMPLOYED&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">365243</span>

<span class="c1"># Replace the anomalous values with nan</span>
<span class="n">app_train</span><span class="p">[</span><span class="s1">&#39;DAYS_EMPLOYED&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">({</span><span class="mi">365243</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">},</span> <span class="n">inplace</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>

<span class="n">app_train</span><span class="p">[</span><span class="s1">&#39;DAYS_EMPLOYED&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">title</span> <span class="o">=</span> <span class="s1">&#39;Days Employment Histogram&#39;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Days Employment&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>The distribution looks to be much more in line with what we would expect, and we also have created a new column to tell the model that these values were originally anomalous (becuase we will have to fill in the nans with some value, probably the median of the column). The other columns with <code class="docutils literal notranslate"><span class="pre">DAYS</span></code> in the dataframe look to be about what we expect with no obvious outliers.</p>
<p>As an extremely important note, anything we do to the training data we also have to do to the testing data. Let’s make sure to create the new column and fill in the existing column with <code class="docutils literal notranslate"><span class="pre">np.nan</span></code> in the testing data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">app_test</span><span class="p">[</span><span class="s1">&#39;DAYS_EMPLOYED_ANOM&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">app_test</span><span class="p">[</span><span class="s2">&quot;DAYS_EMPLOYED&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">365243</span>
<span class="n">app_test</span><span class="p">[</span><span class="s2">&quot;DAYS_EMPLOYED&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">({</span><span class="mi">365243</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">},</span> <span class="n">inplace</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;There are </span><span class="si">%d</span><span class="s1"> anomalies in the test data out of </span><span class="si">%d</span><span class="s1"> entries&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">app_test</span><span class="p">[</span><span class="s2">&quot;DAYS_EMPLOYED_ANOM&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span> <span class="nb">len</span><span class="p">(</span><span class="n">app_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="correlations">
<h3>Correlations<a class="headerlink" href="#correlations" title="Permalink to this headline">¶</a></h3>
<p>Now that we have dealt with the categorical variables and the outliers, let’s continue with the EDA. One way to try and understand the data is by looking for correlations between the features and the target. We can calculate the Pearson correlation coefficient between every variable and the target using the <code class="docutils literal notranslate"><span class="pre">.corr</span></code> dataframe method.</p>
<p>The correlation coefficient is not the greatest method to represent “relevance” of a feature, but it does give us an idea of possible relationships within the data. Some <a class="reference external" href="http://www.statstutor.ac.uk/resources/uploaded/pearsons.pdf">general interpretations of the absolute value of the correlation coefficent</a> are:</p>
<ul class="simple">
<li><p>.00-.19 “very weak”</p></li>
<li><p>.20-.39 “weak”</p></li>
<li><p>.40-.59 “moderate”</p></li>
<li><p>.60-.79 “strong”</p></li>
<li><p>.80-1.0 “very strong”</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Find correlations with the target and sort</span>
<span class="n">correlations</span> <span class="o">=</span> <span class="n">app_train</span><span class="o">.</span><span class="n">corr</span><span class="p">()[</span><span class="s1">&#39;TARGET&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">sort_values</span><span class="p">()</span>

<span class="c1"># Display correlations</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Most Positive Correlations:</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">correlations</span><span class="o">.</span><span class="n">tail</span><span class="p">(</span><span class="mi">15</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Most Negative Correlations:</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">correlations</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">15</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s take a look at some of more significant correlations: the <code class="docutils literal notranslate"><span class="pre">DAYS_BIRTH</span></code> is the most positive correlation. (except for <code class="docutils literal notranslate"><span class="pre">TARGET</span></code> because the correlation of a variable with itself is always 1!) Looking at the documentation, <code class="docutils literal notranslate"><span class="pre">DAYS_BIRTH</span></code> is the age in days of the client at the time of the loan in negative days (for whatever reason!). The correlation is positive, but the value of this feature is actually negative, meaning that as the client gets older, they are less likely to default on their loan (ie the target == 0). That’s a little confusing, so we will take the absolute value of the feature and then the correlation will be negative.</p>
</div>
<div class="section" id="effect-of-age-on-repayment">
<h3>Effect of Age on Repayment<a class="headerlink" href="#effect-of-age-on-repayment" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Find the correlation of the positive days since birth and target</span>
<span class="n">app_train</span><span class="p">[</span><span class="s1">&#39;DAYS_BIRTH&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">app_train</span><span class="p">[</span><span class="s1">&#39;DAYS_BIRTH&#39;</span><span class="p">])</span>
<span class="n">app_train</span><span class="p">[</span><span class="s1">&#39;DAYS_BIRTH&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">corr</span><span class="p">(</span><span class="n">app_train</span><span class="p">[</span><span class="s1">&#39;TARGET&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>As the client gets older, there is a negative linear relationship with the target meaning that as clients get older, they tend to repay their loans on time more often.</p>
<p>Let’s start looking at this variable. First, we can make a histogram of the age. We will put the x axis in years to make the plot a little more understandable.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the style of plots</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;fivethirtyeight&#39;</span><span class="p">)</span>

<span class="c1"># Plot the distribution of ages in years</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">app_train</span><span class="p">[</span><span class="s1">&#39;DAYS_BIRTH&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="mi">365</span><span class="p">,</span> <span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">bins</span> <span class="o">=</span> <span class="mi">25</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Age of Client&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Age (years)&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Count&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>By itself, the distribution of age does not tell us much other than that there are no outliers as all the ages are reasonable. To visualize the effect of the age on the target, we will next make a <a class="reference external" href="https://en.wikipedia.org/wiki/Kernel_density_estimation">kernel density estimation plot</a> (KDE) colored by the value of the target. A <a class="reference external" href="https://chemicalstatistician.wordpress.com/2013/06/09/exploratory-data-analysis-kernel-density-estimation-in-r-on-ozone-pollution-data-in-new-york-and-ozonopolis/">kernel density estimate plot shows the distribution of a single variable</a> and can be thought of as a smoothed histogram (it is created by computing a kernel, usually a Gaussian, at each data point and then averaging all the individual kernels to develop a single smooth curve). We will use the seaborn <code class="docutils literal notranslate"><span class="pre">kdeplot</span></code> for this graph.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>

<span class="c1"># KDE plot of loans that were repaid on time</span>
<span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">app_train</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">app_train</span><span class="p">[</span><span class="s1">&#39;TARGET&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;DAYS_BIRTH&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="mi">365</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;target == 0&#39;</span><span class="p">)</span>

<span class="c1"># KDE plot of loans which were not repaid on time</span>
<span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">app_train</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">app_train</span><span class="p">[</span><span class="s1">&#39;TARGET&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;DAYS_BIRTH&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="mi">365</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;target == 1&#39;</span><span class="p">)</span>

<span class="c1"># Labeling of plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Age (years)&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Density&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Distribution of Ages&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>The target == 1 curve skews towards the younger end of the range. Although this is not a significant correlation (-0.07 correlation coefficient), this variable is likely going to be useful in a machine learning model because it does affect the target. Let’s look at this relationship in another way: average failure to repay loans by age bracket.</p>
<p>To make this graph, first we <code class="docutils literal notranslate"><span class="pre">cut</span></code> the age category into bins of 5 years each. Then, for each bin, we calculate the average value of the target, which tells us the ratio of loans that were not repaid in each age category.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Age information into a separate dataframe</span>
<span class="n">age_data</span> <span class="o">=</span> <span class="n">app_train</span><span class="p">[[</span><span class="s1">&#39;TARGET&#39;</span><span class="p">,</span> <span class="s1">&#39;DAYS_BIRTH&#39;</span><span class="p">]]</span>
<span class="n">age_data</span><span class="p">[</span><span class="s1">&#39;YEARS_BIRTH&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">age_data</span><span class="p">[</span><span class="s1">&#39;DAYS_BIRTH&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="mi">365</span>

<span class="c1"># Bin the age data</span>
<span class="n">age_data</span><span class="p">[</span><span class="s1">&#39;YEARS_BINNED&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">cut</span><span class="p">(</span><span class="n">age_data</span><span class="p">[</span><span class="s1">&#39;YEARS_BIRTH&#39;</span><span class="p">],</span> <span class="n">bins</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">70</span><span class="p">,</span> <span class="n">num</span> <span class="o">=</span> <span class="mi">11</span><span class="p">))</span>
<span class="n">age_data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Group by the bin and calculate averages</span>
<span class="n">age_groups</span>  <span class="o">=</span> <span class="n">age_data</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;YEARS_BINNED&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">age_groups</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>

<span class="c1"># Graph the age bins and the average of the target as a bar plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">age_groups</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">),</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">age_groups</span><span class="p">[</span><span class="s1">&#39;TARGET&#39;</span><span class="p">])</span>

<span class="c1"># Plot labeling</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span> <span class="o">=</span> <span class="mi">75</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Age Group (years)&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Failure to Repay (%)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Failure to Repay by Age Group&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>There is a clear trend: younger applicants are more likely to not repay the loan! The rate of failure to repay is above 10% for the youngest three age groups and beolow 5% for the oldest age group.</p>
<p>This is information that could be directly used by the bank: because younger clients are less likely to repay the loan, maybe they should be provided with more guidance or financial planning tips. This does not mean the bank should discriminate against younger clients, but it would be smart to take precautionary measures to help younger clients pay on time.</p>
</div>
<div class="section" id="exterior-sources">
<h3>Exterior Sources<a class="headerlink" href="#exterior-sources" title="Permalink to this headline">¶</a></h3>
<p>The 3 variables with the strongest negative correlations with the target are <code class="docutils literal notranslate"><span class="pre">EXT_SOURCE_1</span></code>, <code class="docutils literal notranslate"><span class="pre">EXT_SOURCE_2</span></code>, and <code class="docutils literal notranslate"><span class="pre">EXT_SOURCE_3</span></code>.
According to the documentation, these features represent a “normalized score from external data source”. I’m not sure what this exactly means, but it may be a cumulative sort of credit rating made using numerous sources of data.</p>
<p>Let’s take a look at these variables.</p>
<p>First, we can show the correlations of the <code class="docutils literal notranslate"><span class="pre">EXT_SOURCE</span></code> features with the target and with each other.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Extract the EXT_SOURCE variables and show correlations</span>
<span class="n">ext_data</span> <span class="o">=</span> <span class="n">app_train</span><span class="p">[[</span><span class="s1">&#39;TARGET&#39;</span><span class="p">,</span> <span class="s1">&#39;EXT_SOURCE_1&#39;</span><span class="p">,</span> <span class="s1">&#39;EXT_SOURCE_2&#39;</span><span class="p">,</span> <span class="s1">&#39;EXT_SOURCE_3&#39;</span><span class="p">,</span> <span class="s1">&#39;DAYS_BIRTH&#39;</span><span class="p">]]</span>
<span class="n">ext_data_corrs</span> <span class="o">=</span> <span class="n">ext_data</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span>
<span class="n">ext_data_corrs</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="c1"># Heatmap of correlations</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">ext_data_corrs</span><span class="p">,</span> <span class="n">cmap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">RdYlBu_r</span><span class="p">,</span> <span class="n">vmin</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">annot</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">vmax</span> <span class="o">=</span> <span class="mf">0.6</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Correlation Heatmap&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>All three <code class="docutils literal notranslate"><span class="pre">EXT_SOURCE</span></code> featureshave negative correlations with the target, indicating that as the value of the <code class="docutils literal notranslate"><span class="pre">EXT_SOURCE</span></code> increases, the client is more likely to repay the loan. We can also see that <code class="docutils literal notranslate"><span class="pre">DAYS_BIRTH</span></code> is positively correlated with <code class="docutils literal notranslate"><span class="pre">EXT_SOURCE_1</span></code> indicating that maybe one of the factors in this score is the client age.</p>
<p>Next we can look at the distribution of each of these features colored by the value of the target. This will let us visualize the effect of this variable on the target.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">12</span><span class="p">))</span>

<span class="c1"># iterate through the sources</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">source</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">([</span><span class="s1">&#39;EXT_SOURCE_1&#39;</span><span class="p">,</span> <span class="s1">&#39;EXT_SOURCE_2&#39;</span><span class="p">,</span> <span class="s1">&#39;EXT_SOURCE_3&#39;</span><span class="p">]):</span>
    
    <span class="c1"># create a new subplot for each source</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="c1"># plot repaid loans</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">app_train</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">app_train</span><span class="p">[</span><span class="s1">&#39;TARGET&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="n">source</span><span class="p">],</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;target == 0&#39;</span><span class="p">)</span>
    <span class="c1"># plot loans that were not repaid</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">app_train</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">app_train</span><span class="p">[</span><span class="s1">&#39;TARGET&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="n">source</span><span class="p">],</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;target == 1&#39;</span><span class="p">)</span>
    
    <span class="c1"># Label the plots</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Distribution of </span><span class="si">%s</span><span class="s1"> by Target Value&#39;</span> <span class="o">%</span> <span class="n">source</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">source</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Density&#39;</span><span class="p">);</span>
    
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">(</span><span class="n">h_pad</span> <span class="o">=</span> <span class="mf">2.5</span><span class="p">)</span>
    
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">EXT_SOURCE_3</span></code> displays the greatest difference between the values of the target. We can clearly see that this feature has some relationship to the likelihood of an applicant to repay a loan. The relationship is not very strong (in fact they are all <a class="reference external" href="http://www.statstutor.ac.uk/resources/uploaded/pearsons.pdf">considered very weak</a>, but these variables will still be useful for a machine learning model to predict whether or not an applicant will repay a loan on time.</p>
</div>
</div>
<div class="section" id="pairs-plot">
<h2>Pairs Plot<a class="headerlink" href="#pairs-plot" title="Permalink to this headline">¶</a></h2>
<p>As a final exploratory plot, we can make a pairs plot of the <code class="docutils literal notranslate"><span class="pre">EXT_SOURCE</span></code> variables and the <code class="docutils literal notranslate"><span class="pre">DAYS_BIRTH</span></code> variable. The <a class="reference external" href="https://towardsdatascience.com/visualizing-data-with-pair-plots-in-python-f228cf529166">Pairs Plot</a> is a great exploration tool because it lets us see relationships between multiple pairs of variables as well as distributions of single variables. Here we are using the seaborn visualization library and the PairGrid function to create a Pairs Plot with scatterplots on the upper triangle, histograms on the diagonal, and 2D kernel density plots and correlation coefficients on the lower triangle.</p>
<p>If you don’t understand this code, that’s all right! Plotting in Python can be overly complex, and for anything beyond the simplest graphs, I usually find an existing implementation and adapt the code (don’t repeat yourself)!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Copy the data for plotting</span>
<span class="n">plot_data</span> <span class="o">=</span> <span class="n">ext_data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;DAYS_BIRTH&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

<span class="c1"># Add in the age of the client in years</span>
<span class="n">plot_data</span><span class="p">[</span><span class="s1">&#39;YEARS_BIRTH&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">age_data</span><span class="p">[</span><span class="s1">&#39;YEARS_BIRTH&#39;</span><span class="p">]</span>

<span class="c1"># Drop na values and limit to first 100000 rows</span>
<span class="n">plot_data</span> <span class="o">=</span> <span class="n">plot_data</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span><span class="o">.</span><span class="n">loc</span><span class="p">[:</span><span class="mi">100000</span><span class="p">,</span> <span class="p">:]</span>

<span class="c1"># Function to calculate correlation coefficient between two columns</span>
<span class="k">def</span> <span class="nf">corr_func</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s2">&quot;r = </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">r</span><span class="p">),</span>
                <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="o">.</span><span class="mi">2</span><span class="p">,</span> <span class="o">.</span><span class="mi">8</span><span class="p">),</span> <span class="n">xycoords</span><span class="o">=</span><span class="n">ax</span><span class="o">.</span><span class="n">transAxes</span><span class="p">,</span>
                <span class="n">size</span> <span class="o">=</span> <span class="mi">20</span><span class="p">)</span>

<span class="c1"># Create the pairgrid object</span>
<span class="n">grid</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">PairGrid</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">plot_data</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="n">diag_sharey</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="n">hue</span> <span class="o">=</span> <span class="s1">&#39;TARGET&#39;</span><span class="p">,</span> 
                    <span class="nb">vars</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">plot_data</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span> <span class="k">if</span> <span class="n">x</span> <span class="o">!=</span> <span class="s1">&#39;TARGET&#39;</span><span class="p">])</span>

<span class="c1"># Upper is a scatter plot</span>
<span class="n">grid</span><span class="o">.</span><span class="n">map_upper</span><span class="p">(</span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">)</span>

<span class="c1"># Diagonal is a histogram</span>
<span class="n">grid</span><span class="o">.</span><span class="n">map_diag</span><span class="p">(</span><span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">)</span>

<span class="c1"># Bottom is density plot</span>
<span class="n">grid</span><span class="o">.</span><span class="n">map_lower</span><span class="p">(</span><span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">,</span> <span class="n">cmap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">OrRd_r</span><span class="p">);</span>

<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Ext Source and Age Features Pairs Plot&#39;</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="mf">1.05</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>In this plot, the red indicates loans that were not repaid and the blue are loans that are paid. We can see the different relationships within the data. There does appear to be a moderate positive linear relationship between the <code class="docutils literal notranslate"><span class="pre">EXT_SOURCE_1</span></code> and the <code class="docutils literal notranslate"><span class="pre">DAYS_BIRTH</span></code> (or equivalently <code class="docutils literal notranslate"><span class="pre">YEARS_BIRTH</span></code>), indicating that this feature may take into account the age of the client.</p>
</div>
</div>
<div class="section" id="feature-engineering">
<h1>Feature Engineering<a class="headerlink" href="#feature-engineering" title="Permalink to this headline">¶</a></h1>
<p>Kaggle competitions are won by feature engineering: those win are those who can create the most useful features out of the data. (This is true for the most part as the winning models, at least for structured data, all tend to be variants on <a class="reference external" href="http://blog.kaggle.com/2017/01/23/a-kaggle-master-explains-gradient-boosting/">gradient boosting</a>). This represents one of the patterns in machine learning: feature engineering has a greater return on investment than model building and hyperparameter tuning. <a class="reference external" href="https://www.featurelabs.com/blog/secret-to-data-science-success/">This is a great article on the subject)</a>. As Andrew Ng is fond of saying: “applied machine learning is basically feature engineering.”</p>
<p>While choosing the right model and optimal settings are important, the model can only learn from the data it is given. Making sure this data is as relevant to the task as possible is the job of the data scientist (and maybe some <a class="reference external" href="https://docs.featuretools.com/getting_started/install.html">automated tools</a> to help us out).</p>
<p>Feature engineering refers to a geneal process and can involve both feature construction: adding new features from the existing data, and feature selection: choosing only the most important features or other methods of dimensionality reduction. There are many techniques we can use to both create features and select features.</p>
<p>We will do a lot of feature engineering when we start using the other data sources, but in this notebook we will try only two simple feature construction methods:</p>
<ul class="simple">
<li><p>Polynomial features</p></li>
<li><p>Domain knowledge features</p></li>
</ul>
<div class="section" id="polynomial-features">
<h2>Polynomial Features<a class="headerlink" href="#polynomial-features" title="Permalink to this headline">¶</a></h2>
<p>One simple feature construction method is called <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html">polynomial features</a>. In this method, we make features that are powers of existing features as well as interaction terms between existing features. For example, we can create variables <code class="docutils literal notranslate"><span class="pre">EXT_SOURCE_1^2</span></code> and <code class="docutils literal notranslate"><span class="pre">EXT_SOURCE_2^2</span></code> and also variables such as <code class="docutils literal notranslate"><span class="pre">EXT_SOURCE_1</span></code> x <code class="docutils literal notranslate"><span class="pre">EXT_SOURCE_2</span></code>, <code class="docutils literal notranslate"><span class="pre">EXT_SOURCE_1</span></code> x <code class="docutils literal notranslate"><span class="pre">EXT_SOURCE_2^2</span></code>, <code class="docutils literal notranslate"><span class="pre">EXT_SOURCE_1^2</span></code> x   <code class="docutils literal notranslate"><span class="pre">EXT_SOURCE_2^2</span></code>, and so on. These features that are a combination of multiple individual variables are called [interaction terms](https://en.wikipedia.org/wiki/Interaction_(statistics) because they  capture the interactions between variables. In other words, while two variables by themselves  may not have a strong influence on the target, combining them together into a single interaction variable might show a relationship with the target. <a class="reference external" href="https://www.theanalysisfactor.com/interpreting-interactions-in-regression/">Interaction terms are commonly used in statistical models</a> to capture the effects of multiple variables, but I do not see them used as often in machine learning. Nonetheless, we can try out a few to see if they might help our model to predict whether or not a client will repay a loan.</p>
<p>Jake VanderPlas writes about <a class="reference external" href="https://jakevdp.github.io/PythonDataScienceHandbook/05.04-feature-engineering.html">polynomial features in his excellent book Python for Data Science</a> for those who want more information.</p>
<p>In the following code, we create polynomial features using the <code class="docutils literal notranslate"><span class="pre">EXT_SOURCE</span></code> variables and the <code class="docutils literal notranslate"><span class="pre">DAYS_BIRTH</span></code> variable. <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html">Scikit-Learn has a useful class called <code class="docutils literal notranslate"><span class="pre">PolynomialFeatures</span></code></a> that creates the polynomials and the interaction terms up to a specified degree. We can use a degree of 3 to see the results (when we are creating polynomial features, we want to avoid using too high of a degree, both because the number of features scales exponentially with the degree, and because we can run into <a class="reference external" href="http://scikit-learn.org/stable/auto_examples/model_selection/plot_underfitting_overfitting.html#sphx-glr-auto-examples-model-selection-plot-underfitting-overfitting-py">problems with overfitting</a>).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Make a new dataframe for polynomial features</span>
<span class="n">poly_features</span> <span class="o">=</span> <span class="n">app_train</span><span class="p">[[</span><span class="s1">&#39;EXT_SOURCE_1&#39;</span><span class="p">,</span> <span class="s1">&#39;EXT_SOURCE_2&#39;</span><span class="p">,</span> <span class="s1">&#39;EXT_SOURCE_3&#39;</span><span class="p">,</span> <span class="s1">&#39;DAYS_BIRTH&#39;</span><span class="p">,</span> <span class="s1">&#39;TARGET&#39;</span><span class="p">]]</span>
<span class="n">poly_features_test</span> <span class="o">=</span> <span class="n">app_test</span><span class="p">[[</span><span class="s1">&#39;EXT_SOURCE_1&#39;</span><span class="p">,</span> <span class="s1">&#39;EXT_SOURCE_2&#39;</span><span class="p">,</span> <span class="s1">&#39;EXT_SOURCE_3&#39;</span><span class="p">,</span> <span class="s1">&#39;DAYS_BIRTH&#39;</span><span class="p">]]</span>

<span class="c1"># imputer for handling missing values</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">Imputer</span>
<span class="n">imputer</span> <span class="o">=</span> <span class="n">Imputer</span><span class="p">(</span><span class="n">strategy</span> <span class="o">=</span> <span class="s1">&#39;median&#39;</span><span class="p">)</span>

<span class="n">poly_target</span> <span class="o">=</span> <span class="n">poly_features</span><span class="p">[</span><span class="s1">&#39;TARGET&#39;</span><span class="p">]</span>

<span class="n">poly_features</span> <span class="o">=</span> <span class="n">poly_features</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;TARGET&#39;</span><span class="p">])</span>

<span class="c1"># Need to impute missing values</span>
<span class="n">poly_features</span> <span class="o">=</span> <span class="n">imputer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">poly_features</span><span class="p">)</span>
<span class="n">poly_features_test</span> <span class="o">=</span> <span class="n">imputer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">poly_features_test</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">PolynomialFeatures</span>
                                  
<span class="c1"># Create the polynomial object with specified degree</span>
<span class="n">poly_transformer</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span> <span class="o">=</span> <span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Train the polynomial features</span>
<span class="n">poly_transformer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">poly_features</span><span class="p">)</span>

<span class="c1"># Transform the features</span>
<span class="n">poly_features</span> <span class="o">=</span> <span class="n">poly_transformer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">poly_features</span><span class="p">)</span>
<span class="n">poly_features_test</span> <span class="o">=</span> <span class="n">poly_transformer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">poly_features_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Polynomial Features shape: &#39;</span><span class="p">,</span> <span class="n">poly_features</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>This creates a considerable number of new features. To get the names we have to use the polynomial features <code class="docutils literal notranslate"><span class="pre">get_feature_names</span></code> method.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">poly_transformer</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">(</span><span class="n">input_features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;EXT_SOURCE_1&#39;</span><span class="p">,</span> <span class="s1">&#39;EXT_SOURCE_2&#39;</span><span class="p">,</span> <span class="s1">&#39;EXT_SOURCE_3&#39;</span><span class="p">,</span> <span class="s1">&#39;DAYS_BIRTH&#39;</span><span class="p">])[:</span><span class="mi">15</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>There are 35 features with individual features raised to powers up to degree 3 and interaction terms. Now, we can see whether any of these new features are correlated with the target.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create a dataframe of the features </span>
<span class="n">poly_features</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">poly_features</span><span class="p">,</span> 
                             <span class="n">columns</span> <span class="o">=</span> <span class="n">poly_transformer</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">([</span><span class="s1">&#39;EXT_SOURCE_1&#39;</span><span class="p">,</span> <span class="s1">&#39;EXT_SOURCE_2&#39;</span><span class="p">,</span> 
                                                                           <span class="s1">&#39;EXT_SOURCE_3&#39;</span><span class="p">,</span> <span class="s1">&#39;DAYS_BIRTH&#39;</span><span class="p">]))</span>

<span class="c1"># Add in the target</span>
<span class="n">poly_features</span><span class="p">[</span><span class="s1">&#39;TARGET&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">poly_target</span>

<span class="c1"># Find the correlations with the target</span>
<span class="n">poly_corrs</span> <span class="o">=</span> <span class="n">poly_features</span><span class="o">.</span><span class="n">corr</span><span class="p">()[</span><span class="s1">&#39;TARGET&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">sort_values</span><span class="p">()</span>

<span class="c1"># Display most negative and most positive</span>
<span class="nb">print</span><span class="p">(</span><span class="n">poly_corrs</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">poly_corrs</span><span class="o">.</span><span class="n">tail</span><span class="p">(</span><span class="mi">5</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>Several of the new variables have a greater (in terms of absolute magnitude) correlation with the target than the original features. When we build machine learning models, we can try with and without these features to determine if they actually help the model learn.</p>
<p>We will add these features to a copy of the training and testing data and then evaluate models with and without the features. Many times in machine learning, the only way to know if an approach will work is to try it out!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Put test features into dataframe</span>
<span class="n">poly_features_test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">poly_features_test</span><span class="p">,</span> 
                                  <span class="n">columns</span> <span class="o">=</span> <span class="n">poly_transformer</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">([</span><span class="s1">&#39;EXT_SOURCE_1&#39;</span><span class="p">,</span> <span class="s1">&#39;EXT_SOURCE_2&#39;</span><span class="p">,</span> 
                                                                                <span class="s1">&#39;EXT_SOURCE_3&#39;</span><span class="p">,</span> <span class="s1">&#39;DAYS_BIRTH&#39;</span><span class="p">]))</span>

<span class="c1"># Merge polynomial features into training dataframe</span>
<span class="n">poly_features</span><span class="p">[</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">app_train</span><span class="p">[</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">]</span>
<span class="n">app_train_poly</span> <span class="o">=</span> <span class="n">app_train</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">poly_features</span><span class="p">,</span> <span class="n">on</span> <span class="o">=</span> <span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">,</span> <span class="n">how</span> <span class="o">=</span> <span class="s1">&#39;left&#39;</span><span class="p">)</span>

<span class="c1"># Merge polnomial features into testing dataframe</span>
<span class="n">poly_features_test</span><span class="p">[</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">app_test</span><span class="p">[</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">]</span>
<span class="n">app_test_poly</span> <span class="o">=</span> <span class="n">app_test</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">poly_features_test</span><span class="p">,</span> <span class="n">on</span> <span class="o">=</span> <span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">,</span> <span class="n">how</span> <span class="o">=</span> <span class="s1">&#39;left&#39;</span><span class="p">)</span>

<span class="c1"># Align the dataframes</span>
<span class="n">app_train_poly</span><span class="p">,</span> <span class="n">app_test_poly</span> <span class="o">=</span> <span class="n">app_train_poly</span><span class="o">.</span><span class="n">align</span><span class="p">(</span><span class="n">app_test_poly</span><span class="p">,</span> <span class="n">join</span> <span class="o">=</span> <span class="s1">&#39;inner&#39;</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># Print out the new shapes</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Training data with polynomial features shape: &#39;</span><span class="p">,</span> <span class="n">app_train_poly</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Testing data with polynomial features shape:  &#39;</span><span class="p">,</span> <span class="n">app_test_poly</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="id1">
<h2>Domain Knowledge Features<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<p>Maybe it’s not entirely correct to call this “domain knowledge” because I’m not a credit expert, but perhaps we could call this “attempts at applying limited financial knowledge”. In this frame of mind, we can make a couple features that attempt to capture what we think may be important for telling whether a client will default on a loan. Here I’m going to use five features that were inspired by <a class="reference external" href="https://www.kaggle.com/jsaguiar/updated-0-792-lb-lightgbm-with-simple-features">this script</a> by Aguiar:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">CREDIT_INCOME_PERCENT</span></code>: the percentage of the credit amount relative to a client’s income</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ANNUITY_INCOME_PERCENT</span></code>: the percentage of the loan annuity relative to a client’s income</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">CREDIT_TERM</span></code>:  the length of the payment in months (since the annuity is the monthly amount due</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">DAYS_EMPLOYED_PERCENT</span></code>: the percentage of the days employed relative to the client’s age</p></li>
</ul>
<p>Again, thanks to Aguiar and <a class="reference external" href="https://www.kaggle.com/jsaguiar/updated-0-792-lb-lightgbm-with-simple-features">his great script</a> for exploring these features.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">app_train_domain</span> <span class="o">=</span> <span class="n">app_train</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">app_test_domain</span> <span class="o">=</span> <span class="n">app_test</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

<span class="n">app_train_domain</span><span class="p">[</span><span class="s1">&#39;CREDIT_INCOME_PERCENT&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">app_train_domain</span><span class="p">[</span><span class="s1">&#39;AMT_CREDIT&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">app_train_domain</span><span class="p">[</span><span class="s1">&#39;AMT_INCOME_TOTAL&#39;</span><span class="p">]</span>
<span class="n">app_train_domain</span><span class="p">[</span><span class="s1">&#39;ANNUITY_INCOME_PERCENT&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">app_train_domain</span><span class="p">[</span><span class="s1">&#39;AMT_ANNUITY&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">app_train_domain</span><span class="p">[</span><span class="s1">&#39;AMT_INCOME_TOTAL&#39;</span><span class="p">]</span>
<span class="n">app_train_domain</span><span class="p">[</span><span class="s1">&#39;CREDIT_TERM&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">app_train_domain</span><span class="p">[</span><span class="s1">&#39;AMT_ANNUITY&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">app_train_domain</span><span class="p">[</span><span class="s1">&#39;AMT_CREDIT&#39;</span><span class="p">]</span>
<span class="n">app_train_domain</span><span class="p">[</span><span class="s1">&#39;DAYS_EMPLOYED_PERCENT&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">app_train_domain</span><span class="p">[</span><span class="s1">&#39;DAYS_EMPLOYED&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">app_train_domain</span><span class="p">[</span><span class="s1">&#39;DAYS_BIRTH&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">app_test_domain</span><span class="p">[</span><span class="s1">&#39;CREDIT_INCOME_PERCENT&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">app_test_domain</span><span class="p">[</span><span class="s1">&#39;AMT_CREDIT&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">app_test_domain</span><span class="p">[</span><span class="s1">&#39;AMT_INCOME_TOTAL&#39;</span><span class="p">]</span>
<span class="n">app_test_domain</span><span class="p">[</span><span class="s1">&#39;ANNUITY_INCOME_PERCENT&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">app_test_domain</span><span class="p">[</span><span class="s1">&#39;AMT_ANNUITY&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">app_test_domain</span><span class="p">[</span><span class="s1">&#39;AMT_INCOME_TOTAL&#39;</span><span class="p">]</span>
<span class="n">app_test_domain</span><span class="p">[</span><span class="s1">&#39;CREDIT_TERM&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">app_test_domain</span><span class="p">[</span><span class="s1">&#39;AMT_ANNUITY&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">app_test_domain</span><span class="p">[</span><span class="s1">&#39;AMT_CREDIT&#39;</span><span class="p">]</span>
<span class="n">app_test_domain</span><span class="p">[</span><span class="s1">&#39;DAYS_EMPLOYED_PERCENT&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">app_test_domain</span><span class="p">[</span><span class="s1">&#39;DAYS_EMPLOYED&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">app_test_domain</span><span class="p">[</span><span class="s1">&#39;DAYS_BIRTH&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="visualize-new-variables">
<h3>Visualize New Variables<a class="headerlink" href="#visualize-new-variables" title="Permalink to this headline">¶</a></h3>
<p>We should explore these <strong>domain knowledge</strong> variables visually in a graph. For all of these, we will make the same KDE plot colored by the value of the <code class="docutils literal notranslate"><span class="pre">TARGET</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">20</span><span class="p">))</span>
<span class="c1"># iterate through the new features</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">feature</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">([</span><span class="s1">&#39;CREDIT_INCOME_PERCENT&#39;</span><span class="p">,</span> <span class="s1">&#39;ANNUITY_INCOME_PERCENT&#39;</span><span class="p">,</span> <span class="s1">&#39;CREDIT_TERM&#39;</span><span class="p">,</span> <span class="s1">&#39;DAYS_EMPLOYED_PERCENT&#39;</span><span class="p">]):</span>
    
    <span class="c1"># create a new subplot for each source</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="c1"># plot repaid loans</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">app_train_domain</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">app_train_domain</span><span class="p">[</span><span class="s1">&#39;TARGET&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="n">feature</span><span class="p">],</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;target == 0&#39;</span><span class="p">)</span>
    <span class="c1"># plot loans that were not repaid</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">app_train_domain</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">app_train_domain</span><span class="p">[</span><span class="s1">&#39;TARGET&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="n">feature</span><span class="p">],</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;target == 1&#39;</span><span class="p">)</span>
    
    <span class="c1"># Label the plots</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Distribution of </span><span class="si">%s</span><span class="s1"> by Target Value&#39;</span> <span class="o">%</span> <span class="n">feature</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">feature</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Density&#39;</span><span class="p">);</span>
    
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">(</span><span class="n">h_pad</span> <span class="o">=</span> <span class="mf">2.5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>It’s hard to say ahead of time if these new features will be useful. The only way to tell for sure is to try them out!</p>
</div>
</div>
</div>
<div class="section" id="baseline">
<h1>Baseline<a class="headerlink" href="#baseline" title="Permalink to this headline">¶</a></h1>
<p>For a naive baseline, we could guess the same value for all examples on the testing set.  We are asked to predict the probability of not repaying the loan, so if we are entirely unsure, we would guess 0.5 for all observations on the test set. This  will get us a Reciever Operating Characteristic Area Under the Curve (AUC ROC) of 0.5 in the competition (<a class="reference external" href="https://stats.stackexchange.com/questions/266387/can-auc-roc-be-between-0-0-5">random guessing on a classification task will score a 0.5</a>).</p>
<p>Since we already know what score we are going to get, we don’t really need to make a naive baseline guess. Let’s use a slightly more sophisticated model for our actual baseline: Logistic Regression.</p>
<div class="section" id="logistic-regression-implementation">
<h2>Logistic Regression Implementation<a class="headerlink" href="#logistic-regression-implementation" title="Permalink to this headline">¶</a></h2>
<p>Here I will focus on implementing the model rather than explaining the details, but for those who want to learn more about the theory of machine learning algorithms, I recommend both <a class="reference external" href="http://www-bcf.usc.edu/%7Egareth/ISL/">An Introduction to Statistical Learning</a> and <a class="reference external" href="http://shop.oreilly.com/product/0636920052289.do">Hands-On Machine Learning with Scikit-Learn and TensorFlow</a>. Both of these books present the theory and also the code needed to make the models (in R and Python respectively). They both teach with the mindset that the best way to learn is by doing, and they are very effective!</p>
<p>To get a baseline, we will use all of the features after encoding the categorical variables. We will preprocess the data by filling in the missing values (imputation) and normalizing the range of the features (feature scaling). The following code performs both of these preprocessing steps.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span><span class="p">,</span> <span class="n">Imputer</span>

<span class="c1"># Drop the target from the training data</span>
<span class="k">if</span> <span class="s1">&#39;TARGET&#39;</span> <span class="ow">in</span> <span class="n">app_train</span><span class="p">:</span>
    <span class="n">train</span> <span class="o">=</span> <span class="n">app_train</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;TARGET&#39;</span><span class="p">])</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">train</span> <span class="o">=</span> <span class="n">app_train</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    
<span class="c1"># Feature names</span>
<span class="n">features</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>

<span class="c1"># Copy of the testing data</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">app_test</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

<span class="c1"># Median imputation of missing values</span>
<span class="n">imputer</span> <span class="o">=</span> <span class="n">Imputer</span><span class="p">(</span><span class="n">strategy</span> <span class="o">=</span> <span class="s1">&#39;median&#39;</span><span class="p">)</span>

<span class="c1"># Scale each feature to 0-1</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">(</span><span class="n">feature_range</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="c1"># Fit on the training data</span>
<span class="n">imputer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>

<span class="c1"># Transform both training and testing data</span>
<span class="n">train</span> <span class="o">=</span> <span class="n">imputer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">imputer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">app_test</span><span class="p">)</span>

<span class="c1"># Repeat with the scaler</span>
<span class="n">scaler</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>
<span class="n">train</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Training data shape: &#39;</span><span class="p">,</span> <span class="n">train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Testing data shape: &#39;</span><span class="p">,</span> <span class="n">test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We will use <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"><code class="docutils literal notranslate"><span class="pre">LogisticRegression</span></code>from Scikit-Learn</a> for our first model. The only change we will make from the default model settings is to lower the <a class="reference external" href="http://scikit-learn.org/stable/modules/linear_model.html#logistic-regression">regularization parameter</a>, C, which controls the amount of overfitting (a lower value should decrease overfitting). This will get us slightly better results than the default <code class="docutils literal notranslate"><span class="pre">LogisticRegression</span></code>, but it still will set a low bar for any future models.</p>
<p>Here we use the familiar Scikit-Learn modeling syntax: we first create the model, then we train the model using <code class="docutils literal notranslate"><span class="pre">.fit</span></code> and then we make predictions on the testing data using <code class="docutils literal notranslate"><span class="pre">.predict_proba</span></code> (remember that we want probabilities and not a 0 or 1).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>

<span class="c1"># Make the model with the specified regularization parameter</span>
<span class="n">log_reg</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">C</span> <span class="o">=</span> <span class="mf">0.0001</span><span class="p">)</span>

<span class="c1"># Train on the training data</span>
<span class="n">log_reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now that the model has been trained, we can use it to make predictions. We want to predict the probabilities of not paying a loan, so we use the model <code class="docutils literal notranslate"><span class="pre">predict.proba</span></code> method. This returns an m x 2 array where m is the number of observations. The first column is the probability of the target being 0 and the second column is the probability of the target being 1 (so for a single row, the two columns must sum to 1). We want the probability the loan is not repaid, so we will select the second column.</p>
<p>The following code makes the predictions and selects the correct column.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Make predictions</span>
<span class="c1"># Make sure to select the second column only</span>
<span class="n">log_reg_pred</span> <span class="o">=</span> <span class="n">log_reg</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>The predictions must be in the format shown in the <code class="docutils literal notranslate"><span class="pre">sample_submission.csv</span></code> file, where there are only two columns: <code class="docutils literal notranslate"><span class="pre">SK_ID_CURR</span></code> and <code class="docutils literal notranslate"><span class="pre">TARGET</span></code>. We will create a dataframe in this format from the test set and the predictions called <code class="docutils literal notranslate"><span class="pre">submit</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Submission dataframe</span>
<span class="n">submit</span> <span class="o">=</span> <span class="n">app_test</span><span class="p">[[</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">]]</span>
<span class="n">submit</span><span class="p">[</span><span class="s1">&#39;TARGET&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">log_reg_pred</span>

<span class="n">submit</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>The predictions represent a probability between 0 and 1 that the loan will not be repaid. If we were using these predictions to classify applicants, we could set a probability threshold for determining that a loan is risky.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Save the submission to a csv file</span>
<span class="n">submit</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;log_reg_baseline.csv&#39;</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The submission has now been saved to the virtual environment in which our notebook is running. To access the submission, at the end of the notebook, we will hit the blue Commit &amp; Run button at the upper right of the kernel. This runs the entire notebook and then lets us download any files that are created during the run.</p>
<p>Once we run the notebook, the files created are available in the Versions tab under the Output sub-tab. From here, the submission files can be submitted to the competition or downloaded. Since there are several models in this notebook, there will be multiple output files.</p>
<p><strong>The logistic regression baseline should score around 0.671 when submitted.</strong></p>
</div>
<div class="section" id="improved-model-random-forest">
<h2>Improved Model: Random Forest<a class="headerlink" href="#improved-model-random-forest" title="Permalink to this headline">¶</a></h2>
<p>To try and beat the poor performance of our baseline, we can update the algorithm. Let’s try using a Random Forest on the same training data to see how that affects performance. The Random Forest is a much more powerful model especially when we use hundreds of trees. We will use 100 trees in the random forest.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>

<span class="c1"># Make the random forest classifier</span>
<span class="n">random_forest</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_jobs</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Train on the training data</span>
<span class="n">random_forest</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">)</span>

<span class="c1"># Extract feature importances</span>
<span class="n">feature_importance_values</span> <span class="o">=</span> <span class="n">random_forest</span><span class="o">.</span><span class="n">feature_importances_</span>
<span class="n">feature_importances</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;feature&#39;</span><span class="p">:</span> <span class="n">features</span><span class="p">,</span> <span class="s1">&#39;importance&#39;</span><span class="p">:</span> <span class="n">feature_importance_values</span><span class="p">})</span>

<span class="c1"># Make predictions on the test data</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">random_forest</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Make a submission dataframe</span>
<span class="n">submit</span> <span class="o">=</span> <span class="n">app_test</span><span class="p">[[</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">]]</span>
<span class="n">submit</span><span class="p">[</span><span class="s1">&#39;TARGET&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">predictions</span>

<span class="c1"># Save the submission dataframe</span>
<span class="n">submit</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;random_forest_baseline.csv&#39;</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>These predictions will also be available when we run the entire notebook.</p>
<p><strong>This model should score around 0.678 when submitted.</strong></p>
<div class="section" id="make-predictions-using-engineered-features">
<h3>Make Predictions using Engineered Features<a class="headerlink" href="#make-predictions-using-engineered-features" title="Permalink to this headline">¶</a></h3>
<p>The only way to see if the Polynomial Features and Domain knowledge improved the model is to train a test a model on these features! We can then compare the submission performance to that for the model without these features to gauge the effect of our feature engineering.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">poly_features_names</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">app_train_poly</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>

<span class="c1"># Impute the polynomial features</span>
<span class="n">imputer</span> <span class="o">=</span> <span class="n">Imputer</span><span class="p">(</span><span class="n">strategy</span> <span class="o">=</span> <span class="s1">&#39;median&#39;</span><span class="p">)</span>

<span class="n">poly_features</span> <span class="o">=</span> <span class="n">imputer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">app_train_poly</span><span class="p">)</span>
<span class="n">poly_features_test</span> <span class="o">=</span> <span class="n">imputer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">app_test_poly</span><span class="p">)</span>

<span class="c1"># Scale the polynomial features</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">(</span><span class="n">feature_range</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="n">poly_features</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">poly_features</span><span class="p">)</span>
<span class="n">poly_features_test</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">poly_features_test</span><span class="p">)</span>

<span class="n">random_forest_poly</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_jobs</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Train on the training data</span>
<span class="n">random_forest_poly</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">poly_features</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">)</span>

<span class="c1"># Make predictions on the test data</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">random_forest_poly</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">poly_features_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Make a submission dataframe</span>
<span class="n">submit</span> <span class="o">=</span> <span class="n">app_test</span><span class="p">[[</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">]]</span>
<span class="n">submit</span><span class="p">[</span><span class="s1">&#39;TARGET&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">predictions</span>

<span class="c1"># Save the submission dataframe</span>
<span class="n">submit</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;random_forest_baseline_engineered.csv&#39;</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>This model scored 0.678 when submitted to the competition, exactly the same as that without the engineered features. Given these results, it does not appear that our feature construction helped in this case.</p>
<div class="section" id="testing-domain-features">
<h4>Testing Domain Features<a class="headerlink" href="#testing-domain-features" title="Permalink to this headline">¶</a></h4>
<p>Now we can test the domain features we made by hand.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">app_train_domain</span> <span class="o">=</span> <span class="n">app_train_domain</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="s1">&#39;TARGET&#39;</span><span class="p">)</span>

<span class="n">domain_features_names</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">app_train_domain</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>

<span class="c1"># Impute the domainnomial features</span>
<span class="n">imputer</span> <span class="o">=</span> <span class="n">Imputer</span><span class="p">(</span><span class="n">strategy</span> <span class="o">=</span> <span class="s1">&#39;median&#39;</span><span class="p">)</span>

<span class="n">domain_features</span> <span class="o">=</span> <span class="n">imputer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">app_train_domain</span><span class="p">)</span>
<span class="n">domain_features_test</span> <span class="o">=</span> <span class="n">imputer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">app_test_domain</span><span class="p">)</span>

<span class="c1"># Scale the domainnomial features</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">(</span><span class="n">feature_range</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="n">domain_features</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">domain_features</span><span class="p">)</span>
<span class="n">domain_features_test</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">domain_features_test</span><span class="p">)</span>

<span class="n">random_forest_domain</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_jobs</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Train on the training data</span>
<span class="n">random_forest_domain</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">domain_features</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">)</span>

<span class="c1"># Extract feature importances</span>
<span class="n">feature_importance_values_domain</span> <span class="o">=</span> <span class="n">random_forest_domain</span><span class="o">.</span><span class="n">feature_importances_</span>
<span class="n">feature_importances_domain</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;feature&#39;</span><span class="p">:</span> <span class="n">domain_features_names</span><span class="p">,</span> <span class="s1">&#39;importance&#39;</span><span class="p">:</span> <span class="n">feature_importance_values_domain</span><span class="p">})</span>

<span class="c1"># Make predictions on the test data</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">random_forest_domain</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">domain_features_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Make a submission dataframe</span>
<span class="n">submit</span> <span class="o">=</span> <span class="n">app_test</span><span class="p">[[</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">]]</span>
<span class="n">submit</span><span class="p">[</span><span class="s1">&#39;TARGET&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">predictions</span>

<span class="c1"># Save the submission dataframe</span>
<span class="n">submit</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;random_forest_baseline_domain.csv&#39;</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>This scores 0.679 when submitted which probably shows that the engineered features do not help in this model (however they do help in the Gradient Boosting Model at the end of the notebook).</p>
<p>In later notebooks, we will do more <a class="reference external" href="https://docs.featuretools.com/index.html">feature engineering</a> by using the information from the other data sources. From experience, this will definitely help our model!</p>
</div>
</div>
</div>
<div class="section" id="model-interpretation-feature-importances">
<h2>Model Interpretation: Feature Importances<a class="headerlink" href="#model-interpretation-feature-importances" title="Permalink to this headline">¶</a></h2>
<p>As a simple method to see which variables are the most relevant, we can look at the feature importances of the random forest. Given the correlations we saw in the exploratory data analysis, we should expect that the most important features are the <code class="docutils literal notranslate"><span class="pre">EXT_SOURCE</span></code> and the <code class="docutils literal notranslate"><span class="pre">DAYS_BIRTH</span></code>. We may use these feature importances as a method of dimensionality reduction in future work.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_feature_importances</span><span class="p">(</span><span class="n">df</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Plot importances returned by a model. This can work with any measure of</span>
<span class="sd">    feature importance provided that higher importance is better. </span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        df (dataframe): feature importances. Must have the features in a column</span>
<span class="sd">        called `features` and the importances in a column called `importance</span>
<span class="sd">        </span>
<span class="sd">    Returns:</span>
<span class="sd">        shows a plot of the 15 most importance features</span>
<span class="sd">        </span>
<span class="sd">        df (dataframe): feature importances sorted by importance (highest to lowest) </span>
<span class="sd">        with a column for normalized importance</span>
<span class="sd">        &quot;&quot;&quot;</span>
    
    <span class="c1"># Sort features according to importance</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;importance&#39;</span><span class="p">,</span> <span class="n">ascending</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
    
    <span class="c1"># Normalize the feature importances to add up to one</span>
    <span class="n">df</span><span class="p">[</span><span class="s1">&#39;importance_normalized&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;importance&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;importance&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

    <span class="c1"># Make a horizontal bar chart of feature importances</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">()</span>
    
    <span class="c1"># Need to reverse the index to plot most important on top</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">reversed</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="p">[:</span><span class="mi">15</span><span class="p">]))),</span> 
            <span class="n">df</span><span class="p">[</span><span class="s1">&#39;importance_normalized&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">15</span><span class="p">),</span> 
            <span class="n">align</span> <span class="o">=</span> <span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">&#39;k&#39;</span><span class="p">)</span>
    
    <span class="c1"># Set the yticks and labels</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">reversed</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="p">[:</span><span class="mi">15</span><span class="p">]))))</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;feature&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">15</span><span class="p">))</span>
    
    <span class="c1"># Plot labeling</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Normalized Importance&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Feature Importances&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    
    <span class="k">return</span> <span class="n">df</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Show the feature importances for the default features</span>
<span class="n">feature_importances_sorted</span> <span class="o">=</span> <span class="n">plot_feature_importances</span><span class="p">(</span><span class="n">feature_importances</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>As expected, the most important features are those dealing with <code class="docutils literal notranslate"><span class="pre">EXT_SOURCE</span></code> and <code class="docutils literal notranslate"><span class="pre">DAYS_BIRTH</span></code>. We see that there are only a handful of features with a significant importance to the model, which suggests we may be able to drop many of the features without a decrease in performance (and we may even see an increase in performance.) Feature importances are not the most sophisticated method to interpret a model or perform dimensionality reduction, but they let us start to understand what factors our model takes into account when it makes predictions.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">feature_importances_domain_sorted</span> <span class="o">=</span> <span class="n">plot_feature_importances</span><span class="p">(</span><span class="n">feature_importances_domain</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We see that all four of our hand-engineered features made it into the top 15 most important! This should give us confidence that our domain knowledge was at least partially on track.</p>
</div>
</div>
<div class="section" id="conclusions">
<h1>Conclusions<a class="headerlink" href="#conclusions" title="Permalink to this headline">¶</a></h1>
<p>In this notebook, we saw how to get started with a Kaggle machine learning competition. We first made sure to understand the data, our task, and the metric by which our submissions will be judged. Then, we performed a fairly simple EDA to try and identify relationships, trends, or anomalies that may help our modeling. Along the way, we performed necessary preprocessing steps such as encoding categorical variables, imputing missing values, and scaling features to a range. Then, we constructed new features out of the existing data to see if doing so could help our model.</p>
<p>Once the data exploration, data preparation, and feature engineering was complete, we implemented a baseline model upon which we hope to improve. Then we built a second slightly more complicated model to beat our first score. We also carried out an experiment to determine the effect of adding the engineering variables.</p>
<p>We followed the general outline of a <a class="reference external" href="https://towardsdatascience.com/a-complete-machine-learning-walk-through-in-python-part-one-c62152f39420">machine learning project</a>:</p>
<ol class="simple">
<li><p>Understand the problem and the data</p></li>
<li><p>Data cleaning and formatting (this was mostly done for us)</p></li>
<li><p>Exploratory Data Analysis</p></li>
<li><p>Baseline model</p></li>
<li><p>Improved model</p></li>
<li><p>Model interpretation (just a little)</p></li>
</ol>
<p>Machine learning competitions do differ slightly from typical data science problems in that we are concerned only with achieving the best performance on a single metric and do not care about the interpretation. However, by attempting to understand how our models make decisions, we can try to improve them or examine the mistakes in order to correct the errors. In future notebooks we will look at incorporating more sources of data, building more complex models (by following the code of others), and improving our scores.</p>
<p>I hope this notebook was able to get you up and running in this machine learning competition and that you are now ready to go out on your own - with help from the community - and start working on some great problems!</p>
<p><strong>Running the notebook</strong>: now that we are at the end of the notebook, you can hit the blue Commit &amp; Run button to execute all the code at once. After the run is complete (this should take about 10 minutes), you can then access the files that were created by going to the versions tab and then the output sub-tab. The submission files can be directly submitted to the competition from this tab or they can be downloaded to a local machine and saved. The final part is to share the share the notebook: go to the settings tab and change the visibility to Public. This allows the entire world to see your work!</p>
<div class="section" id="follow-up-notebooks">
<h2>Follow-up Notebooks<a class="headerlink" href="#follow-up-notebooks" title="Permalink to this headline">¶</a></h2>
<p>For those looking to keep working on this problem, I have a series of follow-up notebooks:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://www.kaggle.com/willkoehrsen/introduction-to-manual-feature-engineering">Manual Feature Engineering Part One</a></p></li>
<li><p><a class="reference external" href="https://www.kaggle.com/willkoehrsen/introduction-to-manual-feature-engineering-p2">Manual Feature Engineering Part Two</a></p></li>
<li><p><a class="reference external" href="https://www.kaggle.com/willkoehrsen/automated-feature-engineering-basics">Introduction to Automated Feature Engineering</a></p></li>
<li><p><a class="reference external" href="https://www.kaggle.com/willkoehrsen/tuning-automated-feature-engineering-exploratory">Advanced Automated Feature Engineering</a></p></li>
<li><p><a class="reference external" href="https://www.kaggle.com/willkoehrsen/introduction-to-feature-selection">Feature Selection</a></p></li>
<li><p><a class="reference external" href="https://www.kaggle.com/willkoehrsen/intro-to-model-tuning-grid-and-random-search">Intro to Model Tuning: Grid and Random Search</a></p></li>
</ul>
<p>As always, I welcome feedback and constructive criticism. I write for Towards Data Science at https://medium.com/&#64;williamkoehrsen/ and can be reached on Twitter at https://twitter.com/koehrsen_will</p>
<p>Will</p>
</div>
</div>
<div class="section" id="just-for-fun-light-gradient-boosting-machine">
<h1>Just for Fun: Light Gradient Boosting Machine<a class="headerlink" href="#just-for-fun-light-gradient-boosting-machine" title="Permalink to this headline">¶</a></h1>
<p>Now (if you want, this part is entirely optional) we can step off the deep end and use a real machine learning model: the <a class="reference external" href="https://machinelearningmastery.com/gentle-introduction-gradient-boosting-algorithm-machine-learning/">gradient boosting machine</a> using the <a class="reference external" href="http://lightgbm.readthedocs.io/en/latest/Quick-Start.html">LightGBM library</a>! The Gradient Boosting Machine is currently the leading model for learning on structured datasets (especially on Kaggle) and we will probably need some form of this model to do well in the competition. Don’t worry, even if this code looks intimidating, it’s just a series of small steps that build up to a complete model. I added this code just to show what may be in store for this project, and because it gets us a slightly better score on the leaderboard. In future notebooks we will see how to work with more advanced models (which mostly means adapting existing code to make it work better), feature engineering, and feature selection. See you in the next notebook!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span>
<span class="kn">import</span> <span class="nn">lightgbm</span> <span class="k">as</span> <span class="nn">lgb</span>
<span class="kn">import</span> <span class="nn">gc</span>

<span class="k">def</span> <span class="nf">model</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">test_features</span><span class="p">,</span> <span class="n">encoding</span> <span class="o">=</span> <span class="s1">&#39;ohe&#39;</span><span class="p">,</span> <span class="n">n_folds</span> <span class="o">=</span> <span class="mi">5</span><span class="p">):</span>
    
    <span class="sd">&quot;&quot;&quot;Train and test a light gradient boosting model using</span>
<span class="sd">    cross validation. </span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    --------</span>
<span class="sd">        features (pd.DataFrame): </span>
<span class="sd">            dataframe of training features to use </span>
<span class="sd">            for training a model. Must include the TARGET column.</span>
<span class="sd">        test_features (pd.DataFrame): </span>
<span class="sd">            dataframe of testing features to use</span>
<span class="sd">            for making predictions with the model. </span>
<span class="sd">        encoding (str, default = &#39;ohe&#39;): </span>
<span class="sd">            method for encoding categorical variables. Either &#39;ohe&#39; for one-hot encoding or &#39;le&#39; for integer label encoding</span>
<span class="sd">            n_folds (int, default = 5): number of folds to use for cross validation</span>
<span class="sd">        </span>
<span class="sd">    Return</span>
<span class="sd">    --------</span>
<span class="sd">        submission (pd.DataFrame): </span>
<span class="sd">            dataframe with `SK_ID_CURR` and `TARGET` probabilities</span>
<span class="sd">            predicted by the model.</span>
<span class="sd">        feature_importances (pd.DataFrame): </span>
<span class="sd">            dataframe with the feature importances from the model.</span>
<span class="sd">        valid_metrics (pd.DataFrame): </span>
<span class="sd">            dataframe with training and validation metrics (ROC AUC) for each fold and overall.</span>
<span class="sd">        </span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="c1"># Extract the ids</span>
    <span class="n">train_ids</span> <span class="o">=</span> <span class="n">features</span><span class="p">[</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">]</span>
    <span class="n">test_ids</span> <span class="o">=</span> <span class="n">test_features</span><span class="p">[</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">]</span>
    
    <span class="c1"># Extract the labels for training</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">features</span><span class="p">[</span><span class="s1">&#39;TARGET&#39;</span><span class="p">]</span>
    
    <span class="c1"># Remove the ids and target</span>
    <span class="n">features</span> <span class="o">=</span> <span class="n">features</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">,</span> <span class="s1">&#39;TARGET&#39;</span><span class="p">])</span>
    <span class="n">test_features</span> <span class="o">=</span> <span class="n">test_features</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">])</span>
    
    
    <span class="c1"># One Hot Encoding</span>
    <span class="k">if</span> <span class="n">encoding</span> <span class="o">==</span> <span class="s1">&#39;ohe&#39;</span><span class="p">:</span>
        <span class="n">features</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
        <span class="n">test_features</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">test_features</span><span class="p">)</span>
        
        <span class="c1"># Align the dataframes by the columns</span>
        <span class="n">features</span><span class="p">,</span> <span class="n">test_features</span> <span class="o">=</span> <span class="n">features</span><span class="o">.</span><span class="n">align</span><span class="p">(</span><span class="n">test_features</span><span class="p">,</span> <span class="n">join</span> <span class="o">=</span> <span class="s1">&#39;inner&#39;</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
        
        <span class="c1"># No categorical indices to record</span>
        <span class="n">cat_indices</span> <span class="o">=</span> <span class="s1">&#39;auto&#39;</span>
    
    <span class="c1"># Integer label encoding</span>
    <span class="k">elif</span> <span class="n">encoding</span> <span class="o">==</span> <span class="s1">&#39;le&#39;</span><span class="p">:</span>
        
        <span class="c1"># Create a label encoder</span>
        <span class="n">label_encoder</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
        
        <span class="c1"># List for storing categorical indices</span>
        <span class="n">cat_indices</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="c1"># Iterate through each column</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">col</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">features</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">features</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="s1">&#39;object&#39;</span><span class="p">:</span>
                <span class="c1"># Map the categorical features to integers</span>
                <span class="n">features</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">label_encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">features</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,)))</span>
                <span class="n">test_features</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">label_encoder</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">test_features</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,)))</span>

                <span class="c1"># Record the categorical indices</span>
                <span class="n">cat_indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
    
    <span class="c1"># Catch error if label encoding scheme is not valid</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Encoding must be either &#39;ohe&#39; or &#39;le&#39;&quot;</span><span class="p">)</span>
        
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Training Data Shape: &#39;</span><span class="p">,</span> <span class="n">features</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Testing Data Shape: &#39;</span><span class="p">,</span> <span class="n">test_features</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    
    <span class="c1"># Extract feature names</span>
    <span class="n">feature_names</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">features</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
    
    <span class="c1"># Convert to np arrays</span>
    <span class="n">features</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
    <span class="n">test_features</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">test_features</span><span class="p">)</span>
    
    <span class="c1"># Create the kfold object</span>
    <span class="n">k_fold</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span> <span class="o">=</span> <span class="n">n_folds</span><span class="p">,</span> <span class="n">shuffle</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">50</span><span class="p">)</span>
    
    <span class="c1"># Empty array for feature importances</span>
    <span class="n">feature_importance_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">feature_names</span><span class="p">))</span>
    
    <span class="c1"># Empty array for test predictions</span>
    <span class="n">test_predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">test_features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    
    <span class="c1"># Empty array for out of fold validation predictions</span>
    <span class="n">out_of_fold</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    
    <span class="c1"># Lists for recording validation and training scores</span>
    <span class="n">valid_scores</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">train_scores</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="c1"># Iterate through each fold</span>
    <span class="k">for</span> <span class="n">train_indices</span><span class="p">,</span> <span class="n">valid_indices</span> <span class="ow">in</span> <span class="n">k_fold</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">features</span><span class="p">):</span>
        
        <span class="c1"># Training data for the fold</span>
        <span class="n">train_features</span><span class="p">,</span> <span class="n">train_labels</span> <span class="o">=</span> <span class="n">features</span><span class="p">[</span><span class="n">train_indices</span><span class="p">],</span> <span class="n">labels</span><span class="p">[</span><span class="n">train_indices</span><span class="p">]</span>
        <span class="c1"># Validation data for the fold</span>
        <span class="n">valid_features</span><span class="p">,</span> <span class="n">valid_labels</span> <span class="o">=</span> <span class="n">features</span><span class="p">[</span><span class="n">valid_indices</span><span class="p">],</span> <span class="n">labels</span><span class="p">[</span><span class="n">valid_indices</span><span class="p">]</span>
        
        <span class="c1"># Create the model</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">lgb</span><span class="o">.</span><span class="n">LGBMClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">objective</span> <span class="o">=</span> <span class="s1">&#39;binary&#39;</span><span class="p">,</span> 
                                   <span class="n">class_weight</span> <span class="o">=</span> <span class="s1">&#39;balanced&#39;</span><span class="p">,</span> <span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.05</span><span class="p">,</span> 
                                   <span class="n">reg_alpha</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">reg_lambda</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span> 
                                   <span class="n">subsample</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span> <span class="n">n_jobs</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">50</span><span class="p">)</span>
        
        <span class="c1"># Train the model</span>
        <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_features</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">eval_metric</span> <span class="o">=</span> <span class="s1">&#39;auc&#39;</span><span class="p">,</span>
                  <span class="n">eval_set</span> <span class="o">=</span> <span class="p">[(</span><span class="n">valid_features</span><span class="p">,</span> <span class="n">valid_labels</span><span class="p">),</span> <span class="p">(</span><span class="n">train_features</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">)],</span>
                  <span class="n">eval_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;valid&#39;</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">],</span> <span class="n">categorical_feature</span> <span class="o">=</span> <span class="n">cat_indices</span><span class="p">,</span>
                  <span class="n">early_stopping_rounds</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="mi">200</span><span class="p">)</span>
        
        <span class="c1"># Record the best iteration</span>
        <span class="n">best_iteration</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">best_iteration_</span>
        
        <span class="c1"># Record the feature importances</span>
        <span class="n">feature_importance_values</span> <span class="o">+=</span> <span class="n">model</span><span class="o">.</span><span class="n">feature_importances_</span> <span class="o">/</span> <span class="n">k_fold</span><span class="o">.</span><span class="n">n_splits</span>
        
        <span class="c1"># Make predictions</span>
        <span class="n">test_predictions</span> <span class="o">+=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">test_features</span><span class="p">,</span> <span class="n">num_iteration</span> <span class="o">=</span> <span class="n">best_iteration</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">k_fold</span><span class="o">.</span><span class="n">n_splits</span>
        
        <span class="c1"># Record the out of fold predictions</span>
        <span class="n">out_of_fold</span><span class="p">[</span><span class="n">valid_indices</span><span class="p">]</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">valid_features</span><span class="p">,</span> <span class="n">num_iteration</span> <span class="o">=</span> <span class="n">best_iteration</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
        
        <span class="c1"># Record the best score</span>
        <span class="n">valid_score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">best_score_</span><span class="p">[</span><span class="s1">&#39;valid&#39;</span><span class="p">][</span><span class="s1">&#39;auc&#39;</span><span class="p">]</span>
        <span class="n">train_score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">best_score_</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">][</span><span class="s1">&#39;auc&#39;</span><span class="p">]</span>
        
        <span class="n">valid_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">valid_score</span><span class="p">)</span>
        <span class="n">train_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_score</span><span class="p">)</span>
        
        <span class="c1"># Clean up memory</span>
        <span class="n">gc</span><span class="o">.</span><span class="n">enable</span><span class="p">()</span>
        <span class="k">del</span> <span class="n">model</span><span class="p">,</span> <span class="n">train_features</span><span class="p">,</span> <span class="n">valid_features</span>
        <span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
        
    <span class="c1"># Make the submission dataframe</span>
    <span class="n">submission</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">:</span> <span class="n">test_ids</span><span class="p">,</span> <span class="s1">&#39;TARGET&#39;</span><span class="p">:</span> <span class="n">test_predictions</span><span class="p">})</span>
    
    <span class="c1"># Make the feature importance dataframe</span>
    <span class="n">feature_importances</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;feature&#39;</span><span class="p">:</span> <span class="n">feature_names</span><span class="p">,</span> <span class="s1">&#39;importance&#39;</span><span class="p">:</span> <span class="n">feature_importance_values</span><span class="p">})</span>
    
    <span class="c1"># Overall validation score</span>
    <span class="n">valid_auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">out_of_fold</span><span class="p">)</span>
    
    <span class="c1"># Add the overall scores to the metrics</span>
    <span class="n">valid_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">valid_auc</span><span class="p">)</span>
    <span class="n">train_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train_scores</span><span class="p">))</span>
    
    <span class="c1"># Needed for creating dataframe of validation scores</span>
    <span class="n">fold_names</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n_folds</span><span class="p">))</span>
    <span class="n">fold_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;overall&#39;</span><span class="p">)</span>
    
    <span class="c1"># Dataframe of validation scores</span>
    <span class="n">metrics</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;fold&#39;</span><span class="p">:</span> <span class="n">fold_names</span><span class="p">,</span>
                            <span class="s1">&#39;train&#39;</span><span class="p">:</span> <span class="n">train_scores</span><span class="p">,</span>
                            <span class="s1">&#39;valid&#39;</span><span class="p">:</span> <span class="n">valid_scores</span><span class="p">})</span> 
    
    <span class="k">return</span> <span class="n">submission</span><span class="p">,</span> <span class="n">feature_importances</span><span class="p">,</span> <span class="n">metrics</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">submission</span><span class="p">,</span> <span class="n">fi</span><span class="p">,</span> <span class="n">metrics</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">app_train</span><span class="p">,</span> <span class="n">app_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Baseline metrics&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">metrics</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fi_sorted</span> <span class="o">=</span> <span class="n">plot_feature_importances</span><span class="p">(</span><span class="n">fi</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">submission</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;baseline_lgb.csv&#39;</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>This submission should score about 0.735 on the leaderboard. We will certainly best that in future work!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">app_train_domain</span><span class="p">[</span><span class="s1">&#39;TARGET&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">train_labels</span>

<span class="c1"># Test the domain knolwedge features</span>
<span class="n">submission_domain</span><span class="p">,</span> <span class="n">fi_domain</span><span class="p">,</span> <span class="n">metrics_domain</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">app_train_domain</span><span class="p">,</span> <span class="n">app_test_domain</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Baseline with domain knowledge features metrics&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">metrics_domain</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fi_sorted</span> <span class="o">=</span> <span class="n">plot_feature_importances</span><span class="p">(</span><span class="n">fi_domain</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Again, we see tha some of our features made it into the most important. Going forward, we will need to think about whatother domain knowledge features may be useful for this problem (or we should consult someone who knows more about the financial industry!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">submission_domain</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;baseline_lgb_domain_features.csv&#39;</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>This model scores about 0.754 when submitted to the public leaderboard indicating that the domain features do improve the performance! <a class="reference external" href="https://en.wikipedia.org/wiki/Feature_engineering">Feature engineering</a> is going to be a critical part of this competition (as it is for all machine learning problems)!</p>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="landing-page.html" title="previous page">Home Credit Default Risk Assessment</a>
    <a class='right-next' id="next-link" href="application_train_test.html" title="next page">Process train and test files</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By The Jupyter Book community<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="_static/js/index.3da636dd464baa7582d2.js"></script>


    
  </body>
</html>